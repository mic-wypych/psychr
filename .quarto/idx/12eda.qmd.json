{"title":"Exploratory Data Analysis","markdown":{"yaml":{"title":"Exploratory Data Analysis"},"headingText":"getting the basic information about a dataset","containsRefs":false,"markdown":"\n\nUsually once you get the data for your analysis the first thing you want to do is get to know it and briefly browse through it to know e.g. what variables are in the dataset, how many observations you have etc. You might feel the urge to jump right into answering your key research questions. After all, usually data collection is a laborious and tiring process and you are so curious to check what the results are! But it's best to set aside the main analyses for a moment and first take a closer look at the data. Why? It is a necessary steps because there is a near-infinite number of things that can go wrong when preparing the data from errors in how data was coded to errors in preprocessing or loading the files. Lots of things can also happen that can make analysis or drawing conclusions difficult. These can range from issues with your measures (e.g. reliability) through unexpected behaviour of participants during the study (e.g. non-compliance, reactance, purposufely giving ridiculous answers) all the way to errors in the data (e.g. items not recoded or errors in coding, values out of range etc.). Generally exploring the data is not so much about writing/using proper functions but about thinking what could possibly be off with the data to prepare yourself before further analyses.\n\n\nHow to best get to know a new dataset? You can work with datasets from various sources. If it's your study that you're analyzing, then you probably know everything about the variables that should be in it, how many particiapnts took part in the study, how variables are coded etc. However, you might also be working with datasets provided by other people (e.g. by a colleague who ran the study, by a company, or you got the data from an open repository). In these situation it is crucial that you can get to know your data. Many of such datasets will have a codebook available which should describe it in detail. Unfortunately that is not always the case (codebook is like documentation - super important but nobody wants to do it). If a codebook is available, read it (this still does not allow you to skip checking for potential errors/problems with the data). If you don't have a codebook you need to check everything yourself. Fortunately there is a lot of functions in R that make it a lot easier.\n\nLets starts with just general first look at the data. We might want to see how many observations we have, how many columns there are, and the names and types of columns. `dplyr` has a very nice function for it called `glimpse()`. It's more concise than `str()` but gives you more information than e.g. `head()`. Lets load our dataset and have a firsty look at it! We will work with a dataset on wine reviews (the original dataset and its documentation can be found [here](https://www.kaggle.com/datasets/zynicide/wine-reviews)). The dataset has information on country and region of the vineyard, points awarded by reviewers and the price of the wine, as well as variety of the wine.\n\nLets load the dataset, set some base theme for the plots and look at the variables in the dataset:\n\n```{r}\nlibrary(tidyverse)\n\ntheme_set(theme_minimal(base_size = 15))\n\nwine <- read_csv(\"data/wine.csv\")\nglimpse(wine)\n```\n\nThere's plenty of variables but we will focus on 3: country (where the vineyard is located), points (score awarded by reviewer) and price (price of the wine). There is a number of things we might want to look at to get to know the data better. Lets start with the numeric columns. A good point to start is to look at some summary statistics like means, standard deviations, minimum and maximum values (we'll use `knitr::kable()` just to make the table look nicer in the output).\n\n```{r warning=FALSE}\nwine <- wine %>%\n  select(-`...1`)\nwine %>%\n  summarize(across(is.numeric, .fns = list(mean = ~mean(.x, na.rm = T), \n                                           sd = ~sd(.x, na.rm = T),\n                                           min = ~min(.x, na.rm = T), \n                                           max = ~max(.x, na.rm = T)))) %>%\n  knitr::kable()\n```\n\nIt seems that no values are out out range as the documentation says that `points` should be between 1 and 100 and the price seems reasonable as well - from 4 to 2300. Perhaps surprisingly the lowest rating is 80 - this is fairly high for a 1 to 100 scale!\n\nWe can also look at other variables that aren't numeric - lets look at the country variable as an example. Lets see which countries are available and for which countries we have the most reviews. We can do it by combining `count()` with `arrange()`.\n\n```{r}\nwine %>%\n  count(country) %>%\n  arrange(desc(n))\n```\n\nIf we just want to get information on which countries are in the data we can use `unique()`:\n\n```{r}\nunique(wine$country)\n```\n\nThe `psych` package also has a pretty useful function that can give you multiple summaries very quickly. It's called `describe()`. It takes a data frame or a matrix as an argument and can provide a lot of summary statistics for numeric variables such as the mean, median, standard deviation, standard error, skew, kurtosis and quantiles. You can specify which of these you want by setting additional arguments.d\n\n```{r}\nlibrary(psych)\nwine %>%\n  select(where(is.numeric)) %>%\n  describe() %>%\n  knitr::kable()\n```\n\nSometimes you want summary statistics grouped by some categorical variable (e.g. experimental condition). You can do it with `describe.by()` from `psych` package. It works the same way as `describe()` you just need to provide the `group` argument which tells R what variable to split the dataset by. Lets look at a subset of countries (since there are so many!): USA, Italy and France:\n\n```{r}\ndescribeBy(price + points ~ country, data = wine[which(wine$country %in% c(\"US\", \"Italy\", \"France\")),], mat=TRUE)%>%\n  knitr::kable()\n\n```\n\n## Exploring via plots\n\nDoing numeric exploration is always useful and can give you plenty of information about a dataset but in many situations a plot makes exploration much easier. It allows you to immediately spot certain problems like implausible outliers, weird (e.g. censored) distributions or types of relations (is it linear? quadratic? Does it make sense at all?). Lets look at some quick summaries of our variables with plots. We can start by simple histograms of numeric variables and a scatterplot to show the relation between\n\n```{r}\nwine %>%\n  select(price, points) %>%\n  pivot_longer(cols = everything(), names_to = \"var\", values_to = \"value\") %>%\n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 30) +\n  facet_wrap(~var, scales = \"free\")\n```\n\nWe can see that `points` is a nicely normal distribution while the `price` variable is heavily skewed (which is to be expected). Lets look at the scatterplot of the two:\n\n```{r}\nwine %>%\n  ggplot(aes(x = points, y = price)) +\n  geom_point(alpha = .4) +\n  geom_smooth()\n```\n\nSeems that as the score increases the variability in price goes up as well. especially above 90 points. Another good idea might be looktng at price and scores e.g. in different countries. Lets focus again on a subset of countries: US, Italy and France.\n\n```{r}\nwine %>%\n  filter(country %in% c(\"US\", \"Italy\", \"France\")) %>%\n  ggplot(aes(x = country, y = price)) +\n  geom_violin() +\n  geom_boxplot(width = .2)\n```\n\n```{r}\nwine %>%\n  filter(country %in% c(\"US\", \"Italy\", \"France\")) %>%\n  ggplot(aes(x = country, y = points)) +\n  geom_violin() +\n  geom_boxplot(width = .2)\n```\n\nAnd the relation between points and price in each of the three countries:\n\n```{r}\nwine %>%\n  filter(country %in% c(\"US\", \"Italy\", \"France\")) %>%\n  ggplot(aes(x = points, y = price)) +\n  geom_point(alpha = .4) +\n  geom_smooth() +\n  facet_wrap(~country)\n```\n\nLooks like the rise in price for the highest scored wines is driven especially by French wines.\n\n### A cautionary tale the boring way\n\nOne of the reasons why plotting is very important and useful is that all sorts of data can provide you the same point estimate (like a mean or a regression slope). The most common example is the Anscombe quartet. It's a set of 4 datasets with x and y variable each. Each of these have exactly the same correlation coefficient between x and y so you might be tempted to say they are pretty much the same, right? But if you plot them you'll see this:\n\n![](images/paste-E216A64B.png){fig-align=\"center\"}\n\nEven though the regression line is the same on each plot you can immediately see that it makes sense only in the first one (top left). The top right one shows a quadratic and not a linear relation. The bottom left one clearly has an outlier that drives the regression line to be steeper. And the bottom right one shows pretty much no relation because entire variation in x is driven by a single data point. If we didn't plot the data we wouldn't realize just how different these datasets are. You could discover this in some numerical way (e.g. looking at regression diagnostics) but plotting makes it much faster and allows you to immediately spot the problem.\n\n### A cautionary tale the fun way\n\nThere is a more fun way to see the same point that was made by Anscombe. We'll look at an experiment that was conducted to test how displaying information in the media affects attitude towards migrants. The researchers showed participants either a negative article or a neutral one and measured attitudes towards migrants. They also measured general exposure to the media (ie how much media does one consume) because they were interested in the relation between media consumption and attitudes towards migrants. They also recorded gender and age of participants. Lets load the data:\n\n```{r echo=FALSE, message=FALSE}\nexperiment <- read_csv(\"data/att_experiment.csv\")\nglimpse(experiment)\n```\n\nLets look at some summary statistics first:\n\n```{r}\nexperiment %>%\n  group_by(condition) %>%\n  summarise(mean_att = mean(att_migrants),\n            se_att = sd(att_migrants)/sqrt(n())) %>%\n  knitr::kable()\n```\n\nWell, it does not look like there are any meaningful differences between the conditions. We can also plot these differences:\n\n```{r}\nexperiment %>%\n  ggplot(aes(x = condition, y = att_migrants)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"pointrange\") +\n  coord_cartesian(ylim = c(0,5))\n```\n\nThis is a bit disappointing. We could say that we did not reject the null hypothesis and there is no support in the data that reading a negative article affect attitudes towards migrants relative to reading a neutral article. Lets at least look at the correlation between media exposure and attitude towards migrants. Maybe there is something interesting there? We can use the `cor()` function for it:\n\n```{r}\ncor(experiment$media_exposure, experiment$att_migrants)\n```\n\nWell the correlation seems negative and it definitely is not small. Maybe we are finally on to something! So lets finally plot the data to see how it looks like:\n\n```{r}\nexperiment %>%\n  ggplot(aes(x = media_exposure, y = att_migrants)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n```\n\nWhoops! This obviously makes no sense. We get a plot of a gorilla. This dataset is fabricated! This example is taken fully from a paper: Yanai, I, Lercher, M. (2020). A Hypothesis is a liability. *Genome Biology*, 21, 231. What they did was provide students with a very similar dataset as above and randomly assign their students into one of two condition: half the students were asked to test a specific hypothesis and half to just analyze the dataset. The researchers were interested how many students would find the gorilla. They found (although the sample was small) that students who were asked to test specific hypothesis were less likely to find the gorilla in the data than the students that were not assigned a specific hypothesis to test. This of course dos not mean we should throw hypotheses away. However it shows that being too focused on testing very specific things with our data we can miss some really big errors and unless we explore the data properly we might make terrible mistakes.\n\nThe key takeaway is that a lot of things that are wrong or at least problematic can be immediately spotted when you plot the data. e.g. in when comparing two conditions of an experiment you might spot that the whole effect is driven but just a few outliers. Or that some values are out of range. There are of course limits to what a plot can provide (if you want to quantify then you need more than a plot) but they often work very well for initial screening.\n\n## Exercises\n\nDownload the dataset and its codebook\n\n1.  Look at the dataset and its codebook. Try to validate the data and make sure all variables are coded correctly\n2.  Explore the data with plots - does the data look ok?\n","srcMarkdownNoYaml":"\n\nUsually once you get the data for your analysis the first thing you want to do is get to know it and briefly browse through it to know e.g. what variables are in the dataset, how many observations you have etc. You might feel the urge to jump right into answering your key research questions. After all, usually data collection is a laborious and tiring process and you are so curious to check what the results are! But it's best to set aside the main analyses for a moment and first take a closer look at the data. Why? It is a necessary steps because there is a near-infinite number of things that can go wrong when preparing the data from errors in how data was coded to errors in preprocessing or loading the files. Lots of things can also happen that can make analysis or drawing conclusions difficult. These can range from issues with your measures (e.g. reliability) through unexpected behaviour of participants during the study (e.g. non-compliance, reactance, purposufely giving ridiculous answers) all the way to errors in the data (e.g. items not recoded or errors in coding, values out of range etc.). Generally exploring the data is not so much about writing/using proper functions but about thinking what could possibly be off with the data to prepare yourself before further analyses.\n\n## getting the basic information about a dataset\n\nHow to best get to know a new dataset? You can work with datasets from various sources. If it's your study that you're analyzing, then you probably know everything about the variables that should be in it, how many particiapnts took part in the study, how variables are coded etc. However, you might also be working with datasets provided by other people (e.g. by a colleague who ran the study, by a company, or you got the data from an open repository). In these situation it is crucial that you can get to know your data. Many of such datasets will have a codebook available which should describe it in detail. Unfortunately that is not always the case (codebook is like documentation - super important but nobody wants to do it). If a codebook is available, read it (this still does not allow you to skip checking for potential errors/problems with the data). If you don't have a codebook you need to check everything yourself. Fortunately there is a lot of functions in R that make it a lot easier.\n\nLets starts with just general first look at the data. We might want to see how many observations we have, how many columns there are, and the names and types of columns. `dplyr` has a very nice function for it called `glimpse()`. It's more concise than `str()` but gives you more information than e.g. `head()`. Lets load our dataset and have a firsty look at it! We will work with a dataset on wine reviews (the original dataset and its documentation can be found [here](https://www.kaggle.com/datasets/zynicide/wine-reviews)). The dataset has information on country and region of the vineyard, points awarded by reviewers and the price of the wine, as well as variety of the wine.\n\nLets load the dataset, set some base theme for the plots and look at the variables in the dataset:\n\n```{r}\nlibrary(tidyverse)\n\ntheme_set(theme_minimal(base_size = 15))\n\nwine <- read_csv(\"data/wine.csv\")\nglimpse(wine)\n```\n\nThere's plenty of variables but we will focus on 3: country (where the vineyard is located), points (score awarded by reviewer) and price (price of the wine). There is a number of things we might want to look at to get to know the data better. Lets start with the numeric columns. A good point to start is to look at some summary statistics like means, standard deviations, minimum and maximum values (we'll use `knitr::kable()` just to make the table look nicer in the output).\n\n```{r warning=FALSE}\nwine <- wine %>%\n  select(-`...1`)\nwine %>%\n  summarize(across(is.numeric, .fns = list(mean = ~mean(.x, na.rm = T), \n                                           sd = ~sd(.x, na.rm = T),\n                                           min = ~min(.x, na.rm = T), \n                                           max = ~max(.x, na.rm = T)))) %>%\n  knitr::kable()\n```\n\nIt seems that no values are out out range as the documentation says that `points` should be between 1 and 100 and the price seems reasonable as well - from 4 to 2300. Perhaps surprisingly the lowest rating is 80 - this is fairly high for a 1 to 100 scale!\n\nWe can also look at other variables that aren't numeric - lets look at the country variable as an example. Lets see which countries are available and for which countries we have the most reviews. We can do it by combining `count()` with `arrange()`.\n\n```{r}\nwine %>%\n  count(country) %>%\n  arrange(desc(n))\n```\n\nIf we just want to get information on which countries are in the data we can use `unique()`:\n\n```{r}\nunique(wine$country)\n```\n\nThe `psych` package also has a pretty useful function that can give you multiple summaries very quickly. It's called `describe()`. It takes a data frame or a matrix as an argument and can provide a lot of summary statistics for numeric variables such as the mean, median, standard deviation, standard error, skew, kurtosis and quantiles. You can specify which of these you want by setting additional arguments.d\n\n```{r}\nlibrary(psych)\nwine %>%\n  select(where(is.numeric)) %>%\n  describe() %>%\n  knitr::kable()\n```\n\nSometimes you want summary statistics grouped by some categorical variable (e.g. experimental condition). You can do it with `describe.by()` from `psych` package. It works the same way as `describe()` you just need to provide the `group` argument which tells R what variable to split the dataset by. Lets look at a subset of countries (since there are so many!): USA, Italy and France:\n\n```{r}\ndescribeBy(price + points ~ country, data = wine[which(wine$country %in% c(\"US\", \"Italy\", \"France\")),], mat=TRUE)%>%\n  knitr::kable()\n\n```\n\n## Exploring via plots\n\nDoing numeric exploration is always useful and can give you plenty of information about a dataset but in many situations a plot makes exploration much easier. It allows you to immediately spot certain problems like implausible outliers, weird (e.g. censored) distributions or types of relations (is it linear? quadratic? Does it make sense at all?). Lets look at some quick summaries of our variables with plots. We can start by simple histograms of numeric variables and a scatterplot to show the relation between\n\n```{r}\nwine %>%\n  select(price, points) %>%\n  pivot_longer(cols = everything(), names_to = \"var\", values_to = \"value\") %>%\n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 30) +\n  facet_wrap(~var, scales = \"free\")\n```\n\nWe can see that `points` is a nicely normal distribution while the `price` variable is heavily skewed (which is to be expected). Lets look at the scatterplot of the two:\n\n```{r}\nwine %>%\n  ggplot(aes(x = points, y = price)) +\n  geom_point(alpha = .4) +\n  geom_smooth()\n```\n\nSeems that as the score increases the variability in price goes up as well. especially above 90 points. Another good idea might be looktng at price and scores e.g. in different countries. Lets focus again on a subset of countries: US, Italy and France.\n\n```{r}\nwine %>%\n  filter(country %in% c(\"US\", \"Italy\", \"France\")) %>%\n  ggplot(aes(x = country, y = price)) +\n  geom_violin() +\n  geom_boxplot(width = .2)\n```\n\n```{r}\nwine %>%\n  filter(country %in% c(\"US\", \"Italy\", \"France\")) %>%\n  ggplot(aes(x = country, y = points)) +\n  geom_violin() +\n  geom_boxplot(width = .2)\n```\n\nAnd the relation between points and price in each of the three countries:\n\n```{r}\nwine %>%\n  filter(country %in% c(\"US\", \"Italy\", \"France\")) %>%\n  ggplot(aes(x = points, y = price)) +\n  geom_point(alpha = .4) +\n  geom_smooth() +\n  facet_wrap(~country)\n```\n\nLooks like the rise in price for the highest scored wines is driven especially by French wines.\n\n### A cautionary tale the boring way\n\nOne of the reasons why plotting is very important and useful is that all sorts of data can provide you the same point estimate (like a mean or a regression slope). The most common example is the Anscombe quartet. It's a set of 4 datasets with x and y variable each. Each of these have exactly the same correlation coefficient between x and y so you might be tempted to say they are pretty much the same, right? But if you plot them you'll see this:\n\n![](images/paste-E216A64B.png){fig-align=\"center\"}\n\nEven though the regression line is the same on each plot you can immediately see that it makes sense only in the first one (top left). The top right one shows a quadratic and not a linear relation. The bottom left one clearly has an outlier that drives the regression line to be steeper. And the bottom right one shows pretty much no relation because entire variation in x is driven by a single data point. If we didn't plot the data we wouldn't realize just how different these datasets are. You could discover this in some numerical way (e.g. looking at regression diagnostics) but plotting makes it much faster and allows you to immediately spot the problem.\n\n### A cautionary tale the fun way\n\nThere is a more fun way to see the same point that was made by Anscombe. We'll look at an experiment that was conducted to test how displaying information in the media affects attitude towards migrants. The researchers showed participants either a negative article or a neutral one and measured attitudes towards migrants. They also measured general exposure to the media (ie how much media does one consume) because they were interested in the relation between media consumption and attitudes towards migrants. They also recorded gender and age of participants. Lets load the data:\n\n```{r echo=FALSE, message=FALSE}\nexperiment <- read_csv(\"data/att_experiment.csv\")\nglimpse(experiment)\n```\n\nLets look at some summary statistics first:\n\n```{r}\nexperiment %>%\n  group_by(condition) %>%\n  summarise(mean_att = mean(att_migrants),\n            se_att = sd(att_migrants)/sqrt(n())) %>%\n  knitr::kable()\n```\n\nWell, it does not look like there are any meaningful differences between the conditions. We can also plot these differences:\n\n```{r}\nexperiment %>%\n  ggplot(aes(x = condition, y = att_migrants)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"pointrange\") +\n  coord_cartesian(ylim = c(0,5))\n```\n\nThis is a bit disappointing. We could say that we did not reject the null hypothesis and there is no support in the data that reading a negative article affect attitudes towards migrants relative to reading a neutral article. Lets at least look at the correlation between media exposure and attitude towards migrants. Maybe there is something interesting there? We can use the `cor()` function for it:\n\n```{r}\ncor(experiment$media_exposure, experiment$att_migrants)\n```\n\nWell the correlation seems negative and it definitely is not small. Maybe we are finally on to something! So lets finally plot the data to see how it looks like:\n\n```{r}\nexperiment %>%\n  ggplot(aes(x = media_exposure, y = att_migrants)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n```\n\nWhoops! This obviously makes no sense. We get a plot of a gorilla. This dataset is fabricated! This example is taken fully from a paper: Yanai, I, Lercher, M. (2020). A Hypothesis is a liability. *Genome Biology*, 21, 231. What they did was provide students with a very similar dataset as above and randomly assign their students into one of two condition: half the students were asked to test a specific hypothesis and half to just analyze the dataset. The researchers were interested how many students would find the gorilla. They found (although the sample was small) that students who were asked to test specific hypothesis were less likely to find the gorilla in the data than the students that were not assigned a specific hypothesis to test. This of course dos not mean we should throw hypotheses away. However it shows that being too focused on testing very specific things with our data we can miss some really big errors and unless we explore the data properly we might make terrible mistakes.\n\nThe key takeaway is that a lot of things that are wrong or at least problematic can be immediately spotted when you plot the data. e.g. in when comparing two conditions of an experiment you might spot that the whole effect is driven but just a few outliers. Or that some values are out of range. There are of course limits to what a plot can provide (if you want to quantify then you need more than a plot) but they often work very well for initial screening.\n\n## Exercises\n\nDownload the dataset and its codebook\n\n1.  Look at the dataset and its codebook. Try to validate the data and make sure all variables are coded correctly\n2.  Explore the data with plots - does the data look ok?\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"highlight-style":"monokai","output-file":"12eda.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.549","editor":"visual","theme":"theme.scss","toc-location":"left","page-layout":"full","title":"Exploratory Data Analysis"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}