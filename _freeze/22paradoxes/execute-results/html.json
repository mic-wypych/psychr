{
  "hash": "c65f86b5d6a5a227b60934fd5a9f1353",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Paradoxes, Artifacts, Jabberwocks\"\nauthor: \"Michał Wypych\"\n---\n\n\n```         \nBeware the Jabberwock, my son!\n```\n\nThis is a selection of various things you might encounter when running regression models and what might possibly happen. This class is thought as a few examples of statistical analyses that show potential paradoxes and issues you might encounter. It is by no means an exhaustive list (I doubt such a list even exists) but hopefully by going through some examples it will show you some things to be aware of.\n\n## Simpson\n\nThe dataset we will be working with comes from `carData` package and stores information on salaries of professors. The question we will be interested in is \"Does experience measured in years since phd affect the salary of a professor\". Lets load the data and have a look:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(carData)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nsalaries <- carData::Salaries\nglimpse(salaries)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 397\nColumns: 6\n$ rank          <fct> Prof, Prof, AsstProf, Prof, Prof, AssocProf, Prof, Prof,…\n$ discipline    <fct> B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, A, A,…\n$ yrs.since.phd <int> 19, 20, 4, 45, 40, 6, 30, 45, 21, 18, 12, 7, 1, 2, 20, 1…\n$ yrs.service   <int> 18, 16, 3, 39, 41, 6, 23, 45, 20, 18, 8, 2, 1, 0, 18, 3,…\n$ sex           <fct> Male, Male, Male, Male, Male, Male, Male, Male, Male, Fe…\n$ salary        <int> 139750, 173200, 79750, 115000, 141500, 97000, 175000, 14…\n```\n\n\n:::\n:::\n\n\nWe can go ahead and run a simple model that predicts salary with years since phd:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(salary ~ yrs.since.phd, salaries) |>\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = salary ~ yrs.since.phd, data = salaries)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-84171 -19432  -2858  16086 102383 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    91718.7     2765.8  33.162   <2e-16 ***\nyrs.since.phd    985.3      107.4   9.177   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 27530 on 395 degrees of freedom\nMultiple R-squared:  0.1758,\tAdjusted R-squared:  0.1737 \nF-statistic: 84.23 on 1 and 395 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\nOk, looks like each year since phd is related to additional 985.3\\$ of income and a professor just after phd would be expected to ear 91718.7\\$. We can also plot the model to inspect it:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalaries |>\n  ggplot(aes(x = yrs.since.phd, y = salary)) +\n  geom_point(alpha = .4) +\n  geom_smooth(method = \"lm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](22paradoxes_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThe effect seems to be visible (though there is some drop for those who are over 40 years after their phd, maybe the relation is more quadratic?)\n\nLets try to add another variable to the model: the rank of the professor (either assistant, associate or full). Maybe we should adjust for it?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(salary ~ yrs.since.phd + rank, salaries) |>\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = salary ~ yrs.since.phd + rank, data = salaries)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-67148 -16683  -1323  11835 105552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   81186.23    2964.17  27.389  < 2e-16 ***\nyrs.since.phd   -80.37     129.47  -0.621  0.53510    \nrankAssocProf 13932.18    4345.76   3.206  0.00146 ** \nrankProf      47860.42    4412.63  10.846  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23650 on 393 degrees of freedom\nMultiple R-squared:  0.3948,\tAdjusted R-squared:  0.3902 \nF-statistic: 85.47 on 3 and 393 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\nUh oh! When we included rank the effect of years since phd disappeared completely! This might look rather puzzling so lets try to take a look at a plot again. Maybe it will show us something we were missing:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalaries %>%\n  mutate(predicted = lm(salary ~ yrs.since.phd + rank, salaries) |> predict()) %>%\n  ggplot(aes(x = yrs.since.phd, y = predicted, color = rank, group = rank)) +\n  geom_line(size = 2) +\n  geom_point(aes(x = yrs.since.phd, y = salary, color = rank))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](22paradoxes_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nNow this is more illuminating. When we look inside each of the ranks there seems to be no effect of years since phd. So why do we see an overall effect of years since phd? Just looking at the plot you can see that years since phd and rank are very closely related. Basically the more experienced you are the higher your rank. And the higher your rank, the higher your salary.\n\nSuch change of effects within subgroups compared to overall effect is called the Simpson Paradox.\n\n## Berkson\n\n## Regression to the mean\n\n-   make something on pre-post correlations.\n",
    "supporting": [
      "22paradoxes_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}