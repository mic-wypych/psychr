{
  "hash": "a6ff4fc7621341047e00dbd86da43d58",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Postprocessing results\"\nauthor: \"Michał Wypych\"\n---\n\n\nIn the final class we will look at how to post process your models to get exactly what you want from them. In older tutorials or textbooks you could usually read to make models directly interpretable. That meant for example such coding of categorical variables so that the regression coefficient were exactly the contrast you wanted.\n\nWith newer and more versatile software you don't really need to do it this way. You can run a model and then process the results to get exactly what matches your hypothesis e.g. if you want to test a specific contrast from an experiment. Or if you want to compare whether the effect of one variable is significantly stronger than the effect of another variable. This gets especially important once you start working with more complex models (like logistic or ordinal regression) where coefficients themselves aren't easily interpretable.\n\n## General logic\n\nThe packages we will be working with is `broom`, `performance` and (amazing!) `marginaleffects`. The last package also has absolutely incredible documentation so I highly recommend checking out its [website](https://marginaleffects.com/).\n\nThe dataset we will be working with is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(broom)\nlibrary(performance)\nlibrary(marginaleffects)\nlibrary(openintro)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nŁadowanie wymaganego pakietu: airports\nŁadowanie wymaganego pakietu: cherryblossom\nŁadowanie wymaganego pakietu: usdata\n```\n\n\n:::\n:::\n\n\n## Tidying the model\n\nYou may have noticed that results of the `lm()` function is a rather complicated list. It is not easy to work with. Fortunately there is the `broom` package that has functions extremely useful for tidying up the results of such models. We can extract infromation from the model on 3 levels: individual observations, model coefficients or the entire model.\\\nThe first one can be achieved with the `augment()` function which will give us predicted values as well as plenty of diagnostics.\n\n\n::: {.cell}\n\n:::\n\n\nWe can tidy the coefficients using `tidy()`. It will give us a nice data frame with all model coefficients:\n\n\n::: {.cell}\n\n:::\n\n\nFinally we can tidy the model-level information using `glance()`:\n\n\n::: {.cell}\n\n:::\n\n\n## Assessing model performance\n\nThe `performance` package from the `easystats` suite of packages has a host of functions for assessing the performance of models.\n\nWe can extract such values like the R squared, rmse, AIC etc. This can also provide a basis for comparing models.\n\n## Making predictions\n\nSometimes you might want to assess the predictions of your model - how well does it predict? Do predictions for various combinations of independent variables differ from each other?\n\n-   splitting the sample\n\n-   common metrics like rmse, r2\n\n## Marginal effects\n\nAn extremely good and clear introduction to marginal effects with explanation of differences between 2 main packages used for them in R can be found on [Andrew Heiss' blog](https://www.andrewheiss.com/blog/2022/05/20/marginalia/) (although this blog works a lot with logisitc regression). If you want to dive deeper into this topic I highly recommend you read that blog post (as well as documentation of the `marginaleffects` package linked above).\n\n-   What is a marginal effect\n\n-   calculating marginal effect\n\n-   conditional effects\n\n## Contrasts\n\nIn many situations when you work linear model you are interested in testing specific hypotheses.\n\n**For example**\n\n-   A very common mistake is to look at coefficients for two predictors from a model one of which is statistically significant while the other is not and declaring that these coefficients differ significantly. [These are two completely different things](https://stat.columbia.edu/~gelman/research/published/signif4.pdf)! You can make a more principled comparison using `marginaleffects`.\n\n## Working with predictions\n\nIn simple models you might get away with directly interpreting the coefficients but for anything even slightly more complicated things get messy really quickly. It is often much easier to work on predictions from the model rather than directly on the coefficients. It is a good practice to get accustomed to working with predictions even for simple models especially that ultimately they allow you to do more.\n",
    "supporting": [
      "19postprocessing_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}