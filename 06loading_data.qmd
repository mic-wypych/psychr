---
title: "loading_data"
---

## Loading data in R

There are many ways of loading a dataset or file into your R session so that you can use it. How to do it depends mainly on how the data is stored.

When loading a dataset there are generally a few things to consider.

## Loading flat files

We'll start with loading what are called flat files: csv (short for comma separated values) and tsv (tab separated values). Both of these are basically plain text files just structures in a ver specific wayThe name kind of gives away how these formats store data: in csv columns are separated by commas and in tsv columns are separated by tabs. You can see an example of a csv file below:

**Put screenshot of csv file here**

-   How to load csv and tsv files

    -   utils

    -   readr

    -   custom arguments. There's a bunch of things we can customize when loading data into R. Maybe you don't need the entire dataset but only a subset of columns? Or you want to manually specify what types of variables you want? Or maybe the dataset you are using does not have variable names? You can specify all of these things as arguments to the loading functions.

## Loading data from SPSS

Data coming from statistical software can't be loaded in such a simple way as above. Mainly because it stores more information. Here we'll focus on .sav format which is used by SPSS. Apart from rows and columns (observations and variables) .sav format stores additional information e.g. on value labels - it is able to attach labels to numbers (like in Likert scales 1 can refer to 'strongly disagree'). SPSS also allows to specify user-defined missing values (a common practice is to e.g. code missing values with 99).

This means we have to somehow deal with this additional information when loading .sav files. There are essentially two ways to go about it: reduce the amount of information stored or introduce a new type of values that can store this additional information. This first approach is taken by the `foreign` package. The second one is taken by `haven` package. Each of these approaches has some advantages and drawbacks. Stripping labels from values is generally easier and keeps consistency in terms of types of objects you are dealing with. You just keep working with numeric, integer, character or boolean values. The downside is that you lose some information and when e.g. saving a data file back to .sav format you can't restore them.

**Discuss the consequences: you keep types of values native to R but loose information or you introduce a new format of data that keeps the information but might not work with some types of analysis**

### loading data with foreign

Go through loading data in foreign

Please notice though that the documentation for `read.spss()` function in foreign states that it was originally developed in 2000 and does not guarantee compatibility with newer versions of SPSS (whcih hasn't changed much since but still).

By default `foregin` will load data into a list rather than a dataframe. You can load into a data frame by setting the argument `to.data.frame` to `TRUE`. Another useful argument is `use.value.labels` which, if set to `TRUE` will convert the numerical values stored in .sav into their corresponding labels. This is the way foreign deals with labelled values: you can use either numeric values or their labels. In the documentation of the function you can read about additional arguments that control handling of labels.

```{r}
library(foreign)
```

Once we have the data loaded lets see what types of values we have.

### loading data with haven

Haven package deals differently with loading labeled variables. It introduces a new type of variable: haven-labelled data. It is capable of storing both numeric values and labels attached to it **by adding an attribute to the variable with labels.loops_conditionals**

```{r}
library(haven)

```

Now that we have loaded the dataset, lets look at the types of variables we have

## Loading excel files

One additional thing you have to take into account when loading data from excel is that it can store a number of sheets in a single file. This has to be taken into account when loading such file into R.

One of the packages available for loading excel data is `readxl`.

```{r}
library(readxl)
```

## Loading jsons

There are situations in which you might work with data that does not come from simple tables but is stored in completely different way. One example that we'll introduce here is the json format. Json is short for Javascript Object Notation and is a common way of storing data in the web.

Json stores data as key - value pairs. These might not approximate tabular format and can be nested and fairly complicated. This type of data is especially common when downloading data directly from the web (e.g. social media data) or from APIs. You can imagine a file that stores information on each user of a website: their username, password and all posts that they have created along with information on each post like their creation date. It might look something like this:

**Put an image of a json file here**

Because json can be a complicated and nested structure the type of data that best approximates it in R is a list. There are ways to ask R to try and handle such list structure and try to convert it into a data frame but it does not always work. Cleaning an unevenly nested json can be a real pain sometimes!

We'll look at an example of a NASA API that stores information on the number of people currently present on space stations. The package we'll use to load the data is `jsonlite`.

```{r}

```

Notice how the loaded object looks like. It is a list with **...**
