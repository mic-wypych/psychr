[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "This is a website accompanying the Introduction to R course at the Faculty of Psychology at University of Warsaw. The course covers basics of working in R, from the basic operations to fundamental statistics. No knowledge of R is assumed but basic knowledge of statistics is required to follow the course (especially for the latter topics).\nPlease note that this website is not a substitution for the course. It supplements and extends it but cannot replace it."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "r_intro.html",
    "href": "r_intro.html",
    "title": "r_intro",
    "section": "",
    "text": "This chapter introduces R and RStudio and shows you how to perform the most basic operations in R. We’ll go through the basics of what is R, how to navigate in the most common program for working with R called RStudio and we’ll also look into where to look for help when you might need it."
  },
  {
    "objectID": "r_intro.html#what-is-r",
    "href": "r_intro.html#what-is-r",
    "title": "r_intro",
    "section": "What is R?",
    "text": "What is R?\nR is a programming language. It was designed in the 90s mainly with working with data in mind.\n\nR is a programming language that was designed mainly for statistical analyses.\nShort history of R?\n\nSo why bother with R rather than stick to SPSS? There is a number of reasons:\n\nIs open source and free! This becomes especially important when you leave academia and very often can’t work on proprietary software like SPSS.\nHas a great community! The first point also makes it much easier for people to collaborate and create new things for R.\nIs more reproducible! Yes, some proprietary software allows you to write code (like SPSS) but what good is that if you need to buy the software to run it?\nIs more flexible than SPSS. There is generally more things you can do in R and you can customize the code so that it does exactly what you need. Don’t like the defaultsettings? You can change them! If you need to you can just write your own functions to calculate just what you need.\nMore things are being developed in R. Generally more newer stuff is developed in R before it reaches e.g. SPSS.\nIs much faster. Once you start working with large datasets and computation heavy analyses you will need things to run fast. R is pretty good with it (although for some really large things it won’t do and you might want to switch to other programming languages like C++).\n\nYou can download R from here."
  },
  {
    "objectID": "r_intro.html#what-is-rstudio",
    "href": "r_intro.html#what-is-rstudio",
    "title": "r_intro",
    "section": "What is RStudio?",
    "text": "What is RStudio?\nWhile R is a programming language RStudio is an IDE (Integrated Development Environment). Basically, it’s purpose is to make working in R easier and more reproducible. You can download RStudio from here.\nWhen you open RStudio you might see something like this:\n\nWe’ll go through each pane one by one and see what they are used for.\n\n\n\nFirst pane: R scripts\n\n\nThe first pane is where your R scripts are displayed. This is the place where you will most commonly write your code. Scripts are files that contain your code and can be saved.\n\n\n\nSecond pane: console\n\n\nSecond pane is where the console is. That’s where the results of your analyses will appear. You can also write code in the console but you can’t easily save it. Writing code in the console is best if you need to check something quickly and you don’t need it saved. However, it’s best to write the code in the script because then you have all your steps saved and can easily retrace them.\n\n\n\nThird pane\n\n\nThird pane contains a few tabs. The most important for us is the Environment tab. This will by default show the global environment - a place where all the objects that you create in your script are stored (e.g. datasets that you load, results of analyses, plots, etc.). The other tabs show the history (so all the functions you ran), connections to databases and allow access to simple tutorials in R.\n\n\n\nFourth pane\n\n\nFourth pane again contains a few tabs. It’s mainly used for viewing various things that are results of your code. The plots that you create will be displayed here, as well as some other visualizations like tables, maps etc. (the latter two in the Viewer tab). If you look up help for a function (you’ll see in a second how to do that) the documentation for that function will also show up here. You can also view which files are available in your current directory (the place where R will try to look for or save files by default) and the list of available packages."
  },
  {
    "objectID": "r_intro.html#getting-help",
    "href": "r_intro.html#getting-help",
    "title": "r_intro",
    "section": "Getting help",
    "text": "Getting help\nWorking in R, especially in the beginning, might be quite overwhelming. Fortunately there is plenty of places where you can look for help. It’s fairly common to look for help.\nLooking up help\n\nBuilt-in help: you can check the documentation of a function in R by calling ?function_name. The documentation of the function will appear in the help tab. It should contain the basic information on the function: what it does, how it should be called, what arguments the function accepts. It can also contain more detailed information like what is the result of a given function or some examples of how to use it.\nCRAN: short for Comprehensive R Archive Network. You can download the newest version of R from CRAN. It’s also the place where many R packages are stored and can be downloaded from. Documentation of packages can be found there as well. You can visit its website here.\nBooks: there is plenty of great books on R that cover a range of various topics, many of them are available for free on the web. Books allow you to get a much more detailed account of various things you can do in R, they are also often written by people who developed specific packages for doing the things described in the books.\nThe Internet: R community is generally very welcoming and helpful and there is plenty of places where you can look for help on the web, from social media like Twitter to common forums like StackOverflow. One thing to keep in mind about answers from the web is that they do not constitute the ‘official’ solutions so they might be wrong - it’s often a good idea to double check or be sure that you understand the solution proposed by someone on a forum."
  },
  {
    "objectID": "r_intro.html#basic-operations",
    "href": "r_intro.html#basic-operations",
    "title": "r_intro",
    "section": "Basic operations",
    "text": "Basic operations\nNow that we know how the basic interface for working in R looks like and where to look for help if we need it, we can move on to making basic operations in R. As you could see, there are 2 places where we can write code: the console or in the scripts. If you type a command in the console you can run it by pressing enter. In order to run a command from the script go to the line where your command is or highlight it and press ctrl + enter.\nIf you’re feeling like using a very fancy calculator you can turn R into one. All the basic mathematical operations work in the same way. So e.g.\n\n2 + 2\n\n[1] 4\n\n\nOther operations work in a similar way. Raising to a power can be achievied with ^:\n\n2^3 + (3/2)\n\n[1] 9.5\n\n\nOk, so we know we can use R as a calculator. However, that is not very useful."
  },
  {
    "objectID": "r_intro.html#objects",
    "href": "r_intro.html#objects",
    "title": "r_intro",
    "section": "Objects",
    "text": "Objects\n\ncreating objects\nUpdating objects"
  },
  {
    "objectID": "basic_data.html",
    "href": "basic_data.html",
    "title": "Basic data",
    "section": "",
    "text": "Now we have a very fancy calculator lets see what R can actually be more useful for. One of the most basic but at the same time useful things is the ability to save objects in R. An object can be anything with something assigned to it. You can store a number, text or whole datasets in an object. Another way to think about objects is that they are like pointers. You assign a name to an object which then points to something. Whenever you call the name of the object it refers to whatever it points to. This means that you can easily create objects and then make calculations using the objects. These calculations can then be easily reused no matter what is inside the object as long as you don’t get any errors.\n\n\nCreating an object in R is actually very simple. You just assign whatever you want to store in the object to a name you want to use to refer to your object. There are a few ways in which you can make the assignment: <-, = or sometimes ->. After creating an object it should appear in your global environment. When you want to access whatever is stored in your object you can just use the name of the object.\n\n my_first_object <- 1\n my_first_object\n\n[1] 1\n\n\n\n\n\nYou can also easily update/change an object. As a general rule in R you can’t change an object once you created it. The way to actually change it is to recreate an object by assigning a new value to the same name.\n\nmy_object <- 5\nmy_object\n\n[1] 5\n\nmy_object <- 10\nmy_object\n\n[1] 10\n\n\n\n\n\n\n\nYou can perform basic mathematical operations on objects just like you would make them on values. You can also assign such result to a new object\n\nnumber_1 <- 5\nnumber_2 <- 3\nsum_of_numbers <- number_1 + number_2\nsum_of_numbers\n\n[1] 8\n\n\nIf we now update one of the objects and repeat the same command we will get updated result.\n\nnumber_2 <- 1\nsum_of_numbers <- number_1 + number_2\nsum_of_numbers\n\n[1] 6\n\n\n\n\n\nYou can also make a number of logical operations. These will generally either be comparisons (is something larger than something else?) or logical operation (just like logic 101 operations like and, or, not). These operations result in a boolean value.\nComparisons are fairly straightforward. You make them with >, < and =. One thing to remember is that to test equality you need double equality sign: ==. A single = is used for assigning objects:\n\nsmall_object <- 5\nlarge_object <- 10\nsmall_object <= large_object\n\n[1] TRUE\n\nsmall_object == large_object\n\n[1] FALSE\n\n\nThere are a few things to keep in mind when making comparisons, especially of other types of objects. If you compare a true/false value to a number, R will convert the boolean to 0 or 1. If you compare strings R will start with the first letter and if they are the same it will move on to the second letter and so on. Alphabetical order determines which string is ‘larger’. Note that for some special signs (like polish signs etc) this might get weird. Another thing to note is that R is case sensitive - ‘A’ is not the same as ‘a’.\n\n'hello' < 'world'\n\n[1] TRUE\n\n\nThe other type of logical operations allow you to create more complicated comparisons. Generally & evaluates as TRUE only if both parts of the expression are TRUE. | (or) evaluates to true only if at least one part of the expression is TRUE. The last operator is the not one: !. It turns TRUE into FALSE and FALSE into TRUE.\n\nsomething_true <- TRUE\nsomething_false <- FALSE\n\nsomething_true & something_false\n\n[1] FALSE\n\nsomething_true | something_false\n\n[1] TRUE\n\n!something_true\n\n[1] FALSE\n\n\nThese operation will be especially useful when we will be filtering datasets (e.g. we want only those observations that have age higher than some value and come from a given region).\n\n\n\nOne might think that perhaps you can add strings together? Ultimately maybe something will come out of it? Lets test it out:\n\n'hello' + 'world'\n\nError in \"hello\" + \"world\": argument nieliczbowy przekazany do operatora dwuargumentowego\n\n\nYou can’t add strings together the same way you would with numbers. WWorking with strings will require some functions. We’ll dig into more details on functions in the future but for now you can think about them as operations that take some input, do something with it and produce some output. Using function generally looks like this function_name(arguments). Arguments of the functions are the inputs.\nYou can put together two strings using paste0() and cat() functions. If you want to learn more about them you can look up their documentation with ?paste0 and ?cat. Notice that cat() inserts a space between the words and paaste0 does not.\n\ncat('Hello', 'World')\n\nHello World\n\npaste0('Hello', 'World')\n\n[1] \"HelloWorld\""
  },
  {
    "objectID": "storing_data.html",
    "href": "storing_data.html",
    "title": "Storing data",
    "section": "",
    "text": "So far we have worked only with single values. However, usually you want to work with whole sets of values like variables or whole datasets. There is a number of types of data you can encounter in R.\n\n\nThe most basic type of data is a vector. Vectors can store any number of values of the same type. You can create a vector using c() function.\n\nmy_very_first_vector <- c(1,2,3)\nmy_very_first_vector\n\n[1] 1 2 3\n\n\nVectors are ordered: they have a first, second value etc. This means that you can access part of a vector -subset them. Subsetting is accomplished with []. You can get a third element of a vector. You can also subset a range of values from a vector wirh :.\n\nlong_vector <- c(1,2,3,4,5,6,7,8,9,10)\nlong_vector[3:5]\n\n[1] 3 4 5\n\n\nIf you try to put different types of values into one vector R will convert the types to a matching one:\n\nmy_vector <- c(1, TRUE, 'some text')\nmy_vector\n\n[1] \"1\"         \"TRUE\"      \"some text\"\n\n\nOperations on vectors: you can make the same operations on vectors as on single values. One of the great features of R is that by default it will make operations element wise - if you try to add two vectors together then the first element from vector 1 will be added to first element of vector 2 and so on.\n\nnumbers <- c(1,2,3,4,5)\nnumbers2 <- c(6,7,8,9,10)\nnumbers + numbers2\n\n[1]  7  9 11 13 15\n\n\nIf the vectors have different lengths then R will start to recycle values from the shorter vectors. But it will output a warning.\n\nshort_v <- c(1,2,3)\nlong_v <- c(1,2,3,4,5)\nshort_v + long_v\n\nWarning in short_v + long_v: długość dłuszego obiektu nie jest wielokrotnością\ndługości krótszego obiektu\n\n\n[1] 2 4 6 5 7\n\n\n\n\n\nFactors are much like vectors except that they are used for storing categorical values - they have levels. You can create a factor by calling factor() and passing it a vector as an argument.\n\nmy_vector <- c('a', 'b', 'a', 'b')\nmy_factor <- factor(my_vector)\nmy_factor\n\n[1] a b a b\nLevels: a b\n\n\nYou can set levels of a factor or specify order.\n\nordered_vec <- c('low', 'high', 'high', 'low', 'low')\nordered_fac <- factor(ordered_vec, ordered = T)\nordered_fac\n\n[1] low  high high low  low \nLevels: high < low\n\n\nNotice how the output looks different now: it includes information on the order.\n\n\n\nWhat is a matrix?\nMatrices are a bit like vectors but they have two dimensions. They can store only one type of values but they have rows and columns.\nHow to create a matrix?\n\n\n\nSubsetting matrices\nSince we have two dimensions subsetting can work both on rows and matrices. The general idea is still the same but we have to specify whether we are subsetting rows or columns. Rows always come first, columns second separated by a comma.\n\n\n\nIn a day to day analysis you will most likely work with data frames most of the time. A data frame is like a matrix in that it has rows and columns but can store different types of values in each column (so that e.g. you can have some variables that are numeric and others that are text). A different way of thinking about data frames is as a list of vectors of the same length with each vector representing a different variable.\n\n\n\nsubsetting data frames\n\n\n\nLists are the final type of basic data in R. They are the most versatile ones - they can store anything inside of them: single values, vectors, matrices, dataframes or even other lists! One important feature of lists is that they are ordered: you can access their elements by position.\n\n\n\nYou might encounter lists if you need to store a number of different things together. E.g. results of many statistical analyses are stored in lists.\nSubsetting lists can be done the same way\nCreating and subsetting lists"
  },
  {
    "objectID": "r_intro.html#basic-values",
    "href": "r_intro.html#basic-values",
    "title": "r_intro",
    "section": "Basic values",
    "text": "Basic values\nWhen analyzing something or writing a program you will probably encounter a number of different types of values. Above you saw one of them: numeric values. These can store numbers with values after the decimal point.. The other types are:\n\ninteger: it stores numbers without decimal point. They can be created by putting capital l after the number e.g. 3L.\nstring: this type refers to to text values. Text is created using quotation marks e.g. ‘this is text’\nboolean/logical: this type refers to logical values: TRUE or FALSE\n\nThese types form a certain hierarchy: some of them can be converted to other but not the other way around. The reason why this is important is that if R encounters more than one type of value in one operation it will often try to convert the types so that they match. It will do so in a way to create the highest matching type. The hierarchy goes in this way: boolean -> integer -> numeric -> string. All the types can be converted to text but not the other way around. Boolean values are converted so that TRUE = 1 and FALSE = 0. o e.g. if you try to add boolean and numeric value, R will convert the boolean to numeric.\n\nTRUE + 6\n\n[1] 7\n\n\nSome operations can’t be performed on certain types of values, e.g. you can’t multiply two strings. If R encoutners two types it can’t work with it will throw an error.\n\n6 * 'this is gonna throw an error'\n\nError in 6 * \"this is gonna throw an error\": argument nieliczbowy przekazany do operatora dwuargumentowego"
  },
  {
    "objectID": "data_viz_2.html",
    "href": "data_viz_2.html",
    "title": "Data visualization part 2",
    "section": "",
    "text": "We know how to make various plots to display the data and how to control the attributes and scales. Now we’ll move on to additional layers in ggplot2\n\n\nThere are situations in which there is too much information to put it in a single plot.\n\n\n\n\nhow to represent statistics on a plot\nPre-calculating values\nstat_summary\n\n\n\n\nThis layer controls how the coordinates of the plot should be handled. Most likely you are used to plots with the cartesian space: an x and y axis that are perpendicular. However you can change that e.g. by fising the ratio of x to y axis, zooming in on a particualr part of the plot or even bending the axis altogether.\n\n\n\nThe final layer, called theme, controlls all the non-data part of the plot: setting fonts, typeface, text size, controlling the background color, plot legend and the grid.\nThere is a number of pre-specified themes that you can use but you can also control everything manually. You can check the documentation of theme() to see just how many elements you can control.\n\nsome example themes\ncontrolling theme yourself\n\n\n\nA note on working with fonts: if you want to work with more fonts than the built-in ones you will have to load them into R. This can sometimes prove quite problematic.\n\nshowtext package"
  },
  {
    "objectID": "data_viz_1.html",
    "href": "data_viz_1.html",
    "title": "Data visualization part 1",
    "section": "",
    "text": "R is absolutely great for plotting\n\n\n-Describe ggplot2 - part of tidyverse.\nOne of the great things about it is that it breaks down each plot into a number of layers that can be changed (more or less) independently.\n\n\n\n-What is grammar of graphics\n-What layers are there in ggplot2\n-ggplot() starts the plot and each layer is chained together with a +.\n\n\n\n-What are aesthetics\n-What are the basic aesthetics\n\n\n\nAfter providing a dataset and aesthetics we have the variables and their mapping to axes on the plot. However, we still don’t have any shapes to actually represent the data. Do we want a scatter plot? Or maybe a bar plot? Or a line plot? The shapes used to represent the data are defined in the geometry layer. Generally all geometries start with geom_ so for example geom_point() will make a scatter plot while geom_bar() will make a bar plot.\nGeometries differ in what aesthetics they accept. You can look up what these are by looking up help for a given geometry. They also differ in what kinds of variables they expect (any combination of categorical vs continuous variables)\n-What are some common geometries:\nNow we can make our first plot in ggplot!\n\nlibrary(ggplot2)\n\nWarning: pakiet 'ggplot2' został zbudowany w wersji R 4.2.2\n\n\nThere is one more thing about geometries and aesthetics. You can set global aesthetics inside the ggplot() function. If you do so these aesthetics will be used by default by all geometries in that plot. You can also set aesthetics inside a given geometry (in fact you can even set a different dataset for a given geometry; this is what we meant by independence of layers) but then they will be used only for this particular geometry and won’t be inherited by other ones.\nCompare the to plots below. They produce the same result:\n\n\n\nAnd the second plot:\n\n\n\n\n\n\nThere are situations in which you don’t want to set some feature to be represented by a given variable but to set them to a fixed value for the entire plot/geometry. For example you might want to set the color or size of all points in a scatter plot. That’s when you set attributes. They are declared inside geometries but outside of aesthetics.\n\n\n\nOne more thing are functions for working with scales: they allow you to have more control over how each scale is represented (e.g. what the breaks and values are, should the scale be transformed)\n\n\n\nA cautionary tale about the limits: scale functions allow you to\n\n\n\nScale functions also allow you to control the color and fill aesthetics.\n\nDiscuss brewer and viridis packages\n\nWhat to be mindful of when setting color palettes:\n\nhow people perceive color\nwhat information you want to represent (is there some order to the variable, is it divergent etc.)"
  },
  {
    "objectID": "data_wrangling.html",
    "href": "data_wrangling.html",
    "title": "data wrangling",
    "section": "",
    "text": "Now that we have our dataset loaded we can finally get to work with it!\n\n\nWe’ll be working within Tidyverse throughout this course.\n-Explain what tidyverse is\n-How each package functions within tidyverse\nFor now we’ll focus on dplyr.\n\n\n\n-What is the pipe, why it’s useful\n-Native pipe alternative\n\n\n\n-Filter\n-Select\n-Mutate\n-Summarise\n-Group by\n-Arrange\n\n\n\n-Chaining functions together with pipes\nThis already gives us the ability to anwser a number of questions that might be very interesting for analysis.\n\n\n\n-make this section optional: if you want to see how to achieve similar things but without using tiduverse"
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "Functions",
    "section": "",
    "text": "Introduce the subject: most of the time we don’t just build things from scratch\n\n\nThe insides of\n\n\n\nDefault argument\nalternative argument\n… argument\n\n\n\nWhy spend time building your own functions?\n-How to turn a chunk of code into a function\n-Documentation: why it matters, why do it\n\n\n\nSince R has a huge community people are constantly developing new things you can do in R. You don’t have to define everything from scratch."
  },
  {
    "objectID": "join_restructure.html",
    "href": "join_restructure.html",
    "title": "restructuring_and_joining_data",
    "section": "",
    "text": "-separating and uniting variables\n-separate when there is various number of values\n\n\n-Different types of joins\n-Gotchas in joins\n\n\n\n-pivot longer\n-pivot wider"
  },
  {
    "objectID": "loading_data.html",
    "href": "loading_data.html",
    "title": "loading_data",
    "section": "",
    "text": "There are many ways of loading a dataset or file into your R session so that you can use it. How to do it depends mainly on how the data is stored."
  },
  {
    "objectID": "loading_data.html#loading-flat-files",
    "href": "loading_data.html#loading-flat-files",
    "title": "loading_data",
    "section": "Loading flat files",
    "text": "Loading flat files\n\nloading csv and tsv files"
  },
  {
    "objectID": "loading_data.html#loading-data-from-spss",
    "href": "loading_data.html#loading-data-from-spss",
    "title": "loading_data",
    "section": "Loading data from SPSS",
    "text": "Loading data from SPSS\nHaven vs foreign package\nData coming from statistical software can’t be loaded in such a simple way.\nMainly because it stores more information. Here we’ll focus on .sav format which is used by SPSS. Apart from rows and columns (observations and variables) .sav format stores additional information e.g. on value labels - it is able to attach labels to numbers (like in Likert scales 1 can refer to ‘strongly disagree’). SPSS also allows to specify user-defined missing values (a common practice is to e.g. code missing values with 99).\nThis means we have to somehow deal with this additional information when loading .sav files. There are essentially two ways to go about it: reduce the amount of information stored or introduce a new type of values that can store this additional information. This first approach is taken by the foreign package. The second one is taken by haven package.\nDiscuss the consequences: you keep types of values native to R but loose information or you introduce a new format of data that keeps the information but might not work with some types of analysis\n\nloading data with foreign\nGo through loading data in foreign\nPlease notice though that the documentation for read.spss() function in foreign states that it was originally developed in 2000 and does not guarantee compatibility with newer versions of SPSS (whcih hasn’t changed much since but still).\nBy default foregin will load data into a list rather than a dataframe. You can load into a data frame by setting the argument to.data.frame to TRUE. Another useful argument is use.value.labels which, if set to TRUE will convert the numerical values stored in .sav into their corresponding labels. This is the way foreign deals with labelled values: you can use either numeric values or their labels. In the documentation of the function you can read about additional arguments that control handling of labels.\n\nlibrary(foreign)\n\nOnce we have the data loaded lets see what types of values we have.\n\n\nloading data with haven\nHaven package deals differently with loading labeled variables. It introduces a new type of variable: haven-labelled data. It is capable of storing both numeric values and labels attached to it by adding an attribute to the variable with labels.loops_conditionals\n\nlibrary(haven)\n\nNow that we have loaded the dataset, lets look at the types of variables we have"
  },
  {
    "objectID": "loading_data.html#loading-excel-files",
    "href": "loading_data.html#loading-excel-files",
    "title": "loading_data",
    "section": "Loading excel files",
    "text": "Loading excel files\nOne additional thing you have to take into account when loading data from excel is that it can store a number of sheets in a single file. This has to be taken into account when loading such file into R.\nOne of the packages available for loading excel data is readxl.\n\nlibrary(readxl)"
  },
  {
    "objectID": "loading_data.html#loading-jsons",
    "href": "loading_data.html#loading-jsons",
    "title": "loading_data",
    "section": "Loading jsons",
    "text": "Loading jsons\nThere are situations in which you might work with data that does not come from simple tables but is stored in completely different way. One example that we’ll introduce here is the json format. Json is short for Javascript Object Notation and is a common way of storing data in the web.\nJson stores data as key - value pairs. These might not approximate tabular format and can be nested and fairly complicated. This type of data is especially common when downloading data directly from the web (e.g. social media data) or from APIs. You can imagine a file that stores information on each user of a website: their username, password and all posts that they have created along with information on each post like their creation date. It might look something like this:\nPut an image of a json file here\nBecause json can be a complicated and nested structure the type of data that best approximates it in R is a list. There are ways to ask R to try and handle such list structure and try to convert it into a data frame but it does not always work. Cleaning an unevenly nested json can be a real pain sometimes!\nWe’ll look at an example of a NASA API that stores information on the number of people currently present on space stations. The package we’ll use to load the data is jsonlite.\n\n\n\nNotice how the loaded object looks like. It is a list with …"
  },
  {
    "objectID": "loops_conditionals.html",
    "href": "loops_conditionals.html",
    "title": "Loops and conditionals",
    "section": "",
    "text": "Some introduction to what the flow is and why it’s worth knowing how to control it\n\n\nIf statements, if else statements and combinations\n\n\n\nFor loops\nWhile loops\n\n\n\nDesign some code-along example that would show why this might actually be useful. e.g.\n\na simple game?\nSome simple algorithm?\nCalculator-type of thing"
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "Regression",
    "section": "",
    "text": "What type of problems are we talking about?\n-What is a regression analysis?\n\n\nRegression analysis is often described in two ways. One of them talks about how to predict a value of variable of interest given a set of other variables. The other context focuses on inference: which variables are in fact related to a variable of interest.\nHousing market example: imagine you work in a real estate agency selling houses. You track information on a number of characteristics of each house: their price, size, number of rooms, distance from city center and various facilities etc. You might be interested in predicting the price of a house as accurately as possible given all the characteristics of a house. You might also be interested in how various characteristics of a house relate to its price so as to know what to focus on.\n\n\n\nThe very idea of making a regression analysis is ultimately an optimization problem. We want to reexpress the relations between variables so as to be able to express one of them as a combination of the other ones.\n\n\n\n-how to make a regression analysis\n-how to look at the results\n\n\n\n-how to make it\n-Why you should always think first: putting things into regression"
  },
  {
    "objectID": "anova.html",
    "href": "anova.html",
    "title": "Anova",
    "section": "",
    "text": "-many groups, many means\n\n\n-how to make a one-way anova.\n\n\n-What these are and how to make them\n\n\n\n-How these are different from post hocs\n-How to make them\n\n\n\n\n\n\n\n-how to interpret the results\n-plotting results\n-effect size and power"
  },
  {
    "objectID": "correlations.html",
    "href": "correlations.html",
    "title": "correlations",
    "section": "",
    "text": "-what are those"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Some introduction on moving on to section about data analysis.\nExploring and cleaning data is often a necessary and fairly long process\nWhy even bother with it?\nIt is a necessary steps because there is a near-infinite number of things that can go wrong when preparing the data from errors in how data was coded to errors in preprocessing or loading the files. Lots of things can also happen that can make analysis or drawing conclusions difficult (like how reliable are your scales, are the items recoded correctly etc.)"
  },
  {
    "objectID": "eda.html#getting-the-basic-information-about-a-dataset",
    "href": "eda.html#getting-the-basic-information-about-a-dataset",
    "title": "Exploratory Data Analysis",
    "section": "getting the basic information about a dataset",
    "text": "getting the basic information about a dataset\n\nif you have it, start with any documentation on the dataset (like codebooks etc.)\nGetting basic info on the data: glimpse etc.\nDescribe from psych package\nGetting information on categorical variables"
  },
  {
    "objectID": "eda.html#exploring-via-plots",
    "href": "eda.html#exploring-via-plots",
    "title": "Exploratory Data Analysis",
    "section": "Exploring via plots",
    "text": "Exploring via plots\nWhy plotting data is always important\nA cautionary tale the boring way: Anscombe quartet\nThe fun way: Gorilla in the data\nThe key takeaway is that a lot of things that are wrong or at least problematic can be immediately spotted when you plot the data. e.g. in when comparing two conditions of an experiment you might spot that the whole effect is driven but just a few outliers."
  },
  {
    "objectID": "eda.html#reliabilities",
    "href": "eda.html#reliabilities",
    "title": "Exploratory Data Analysis",
    "section": "reliabilities",
    "text": "reliabilities\n-getting reliability analysis with alpha()"
  },
  {
    "objectID": "t-tests.html",
    "href": "t-tests.html",
    "title": "t tests",
    "section": "",
    "text": "-The whole idea behind the t-tests.\nThe logic behind a t test."
  },
  {
    "objectID": "01r_intro.html",
    "href": "01r_intro.html",
    "title": "r_intro",
    "section": "",
    "text": "This chapter introduces R and RStudio and shows you how to perform the most basic operations in R. We’ll go through the basics of what is R, how to navigate in the most common program for working with R called RStudio and we’ll also look into where to look for help when you might need it."
  },
  {
    "objectID": "01r_intro.html#what-is-r",
    "href": "01r_intro.html#what-is-r",
    "title": "r_intro",
    "section": "What is R?",
    "text": "What is R?\nR is a programming language. It was designed in the 90s mainly with working with data in mind.\n\nR is a programming language that was designed mainly for statistical analyses.\nShort history of R?\n\nSo why bother with R rather than stick to SPSS? There is a number of reasons:\n\nIs open source and free! This becomes especially important when you leave academia and very often can’t work on proprietary software like SPSS.\nHas a great community! The first point also makes it much easier for people to collaborate and create new things for R.\nIs more reproducible! Yes, some proprietary software allows you to write code (like SPSS) but what good is that if you need to buy the software to run it?\nIs more flexible than SPSS. There is generally more things you can do in R and you can customize the code so that it does exactly what you need. Don’t like the defaultsettings? You can change them! If you need to you can just write your own functions to calculate just what you need.\nMore things are being developed in R. Generally more newer stuff is developed in R before it reaches e.g. SPSS.\nIs much faster. Once you start working with large datasets and computation heavy analyses you will need things to run fast. R is pretty good with it (although for some really large things it won’t do and you might want to switch to other programming languages like C++).\n\nYou can download R from here."
  },
  {
    "objectID": "01r_intro.html#what-is-rstudio",
    "href": "01r_intro.html#what-is-rstudio",
    "title": "r_intro",
    "section": "What is RStudio?",
    "text": "What is RStudio?\nWhile R is a programming language RStudio is an IDE (Integrated Development Environment). Basically, it’s purpose is to make working in R easier and more reproducible. You can download RStudio from here.\nWhen you open RStudio you might see something like this:\n\nWe’ll go through each pane one by one and see what they are used for.\n\n\n\nFirst pane: R scripts\n\n\nThe first pane is where your R scripts are displayed. This is the place where you will most commonly write your code. Scripts are files that contain your code and can be saved.\n\n\n\nSecond pane: console\n\n\nSecond pane is where the console is. That’s where the results of your analyses will appear. You can also write code in the console but you can’t easily save it. Writing code in the console is best if you need to check something quickly and you don’t need it saved. However, it’s best to write the code in the script because then you have all your steps saved and can easily retrace them.\n\n\n\nThird pane\n\n\nThird pane contains a few tabs. The most important for us is the Environment tab. This will by default show the global environment - a place where all the objects that you create in your script are stored (e.g. datasets that you load, results of analyses, plots, etc.). The other tabs show the history (so all the functions you ran), connections to databases and allow access to simple tutorials in R.\n\n\n\nFourth pane\n\n\nFourth pane again contains a few tabs. It’s mainly used for viewing various things that are results of your code. The plots that you create will be displayed here, as well as some other visualizations like tables, maps etc. (the latter two in the Viewer tab). If you look up help for a function (you’ll see in a second how to do that) the documentation for that function will also show up here. You can also view which files are available in your current directory (the place where R will try to look for or save files by default) and the list of available packages."
  },
  {
    "objectID": "01r_intro.html#getting-help",
    "href": "01r_intro.html#getting-help",
    "title": "r_intro",
    "section": "Getting help",
    "text": "Getting help\nWorking in R, especially in the beginning, might be quite overwhelming. Fortunately there is plenty of places where you can look for help. It’s fairly common to look for help.\nLooking up help\n\nBuilt-in help: you can check the documentation of a function in R by calling ?function_name. The documentation of the function will appear in the help tab. It should contain the basic information on the function: what it does, how it should be called, what arguments the function accepts. It can also contain more detailed information like what is the result of a given function or some examples of how to use it.\nCRAN: short for Comprehensive R Archive Network. You can download the newest version of R from CRAN. It’s also the place where many R packages are stored and can be downloaded from. Documentation of packages can be found there as well. You can visit its website here.\nBooks: there is plenty of great books on R that cover a range of various topics, many of them are available for free on the web. Books allow you to get a much more detailed account of various things you can do in R, they are also often written by people who developed specific packages for doing the things described in the books.\nThe Internet: R community is generally very welcoming and helpful and there is plenty of places where you can look for help on the web, from social media like Twitter to common forums like StackOverflow. One thing to keep in mind about answers from the web is that they do not constitute the ‘official’ solutions so they might be wrong - it’s often a good idea to double check or be sure that you understand the solution proposed by someone on a forum."
  },
  {
    "objectID": "01r_intro.html#basic-operations",
    "href": "01r_intro.html#basic-operations",
    "title": "r_intro",
    "section": "Basic operations",
    "text": "Basic operations\nNow that we know how the basic interface for working in R looks like and where to look for help if we need it, we can move on to making basic operations in R. As you could see, there are 2 places where we can write code: the console or in the scripts. If you type a command in the console you can run it by pressing enter. In order to run a command from the script go to the line where your command is or highlight it and press ctrl + enter.\nIf you’re feeling like using a very fancy calculator you can turn R into one. All the basic mathematical operations work in the same way. So e.g.\n\n2 + 2\n\n[1] 4\n\n\nOther operations work in a similar way. Raising to a power can be achievied with ^:\n\n2^3 + (3/2)\n\n[1] 9.5\n\n\nOk, so we know we can use R as a calculator. However, that is not very useful."
  },
  {
    "objectID": "01r_intro.html#basic-values",
    "href": "01r_intro.html#basic-values",
    "title": "r_intro",
    "section": "Basic values",
    "text": "Basic values\nWhen analyzing something or writing a program you will probably encounter a number of different types of values. Above you saw one of them: numeric values. These can store numbers with values after the decimal point.. The other types are:\n\ninteger: it stores numbers without decimal point. They can be created by putting capital l after the number e.g. 3L.\nstring: this type refers to to text values. Text is created using quotation marks e.g. ‘this is text’\nboolean/logical: this type refers to logical values: TRUE or FALSE\n\nThese types form a certain hierarchy: some of them can be converted to other but not the other way around. The reason why this is important is that if R encounters more than one type of value in one operation it will often try to convert the types so that they match. It will do so in a way to create the highest matching type. The hierarchy goes in this way: boolean -> integer -> numeric -> string. All the types can be converted to text but not the other way around. Boolean values are converted so that TRUE = 1 and FALSE = 0. o e.g. if you try to add boolean and numeric value, R will convert the boolean to numeric.\n\nTRUE + 6\n\n[1] 7\n\n\nSome operations can’t be performed on certain types of values, e.g. you can’t multiply two strings. If R encoutners two types it can’t work with it will throw an error.\n\n6 * 'this is gonna throw an error'\n\nError in 6 * \"this is gonna throw an error\": argument nieliczbowy przekazany do operatora dwuargumentowego\n\n\nWhoops, we got our first error. An error means that R was not able to execute your command and stopped. You won’t get results of the operation if you get an error (which is different from getting a warning! A warning means that something happened that R wants to tell you about: e.g. it encountered something unusual and had to deal with it in a certain way. Warnings will start with the word Warning. Sometimes it may be a bit confusing because depending on you color settings errors and warnings may be displayed in the same color and it can be a bit scary in the beginning if you get flashing red letter saying something went wrong).\nGenerally an error message will tell you 2 things:\n\nWhere the error happened (in our case in the 6 * 'this is gonna throw an error' line)\nWhat the error is (in our case non-numeric argument to binary operator which just means we used something that is not a number in an operation that requires numbers).\n\nHow exactly an error message is structured largely depends on how well the functions were prepared. If the functions you use are well documented then the error messages should be pretty clear and understandable (which unfortunately is not always the case. This is another reason to document functions well when you start writing your own functions. Be nice to people who start using them!)."
  },
  {
    "objectID": "02data_types.html",
    "href": "02data_types.html",
    "title": "Basic data",
    "section": "",
    "text": "Now we have a very fancy calculator lets see what R can actually be more useful for. One of the most basic but at the same time useful things is the ability to save objects in R. An object can be anything with something assigned to it. You can store a number, text or whole datasets in an object. Another way to think about objects is that they are like pointers. You assign a name to an object which then points to something. Whenever you call the name of the object it refers to whatever it points to. This means that you can easily create objects and then make calculations using the objects. These calculations can then be easily reused no matter what is inside the object as long as you don’t get any errors.\n\n\nCreating an object in R is actually very simple. You just assign whatever you want to store in the object to a name you want to use to refer to your object. There are a few ways in which you can make the assignment: <-, = or sometimes ->. After creating an object it should appear in your global environment. When you want to access whatever is stored in your object you can just use the name of the object.\n\n my_first_object <- 1\n my_first_object\n\n[1] 1\n\n\n\n\n\nYou can also easily update/change an object. As a general rule in R you can’t change an object once you created it. The way to actually change it is to recreate an object by assigning a new value to the same name.\n\nmy_object <- 5\nmy_object\n\n[1] 5\n\nmy_object <- 10\nmy_object\n\n[1] 10\n\n\n\n\n\n\n\nYou can perform basic mathematical operations on objects just like you would make them on values. You can also assign such result to a new object\n\nnumber_1 <- 5\nnumber_2 <- 3\nsum_of_numbers <- number_1 + number_2\nsum_of_numbers\n\n[1] 8\n\n\nIf we now update one of the objects and repeat the same command we will get updated result.\n\nnumber_2 <- 1\nsum_of_numbers <- number_1 + number_2\nsum_of_numbers\n\n[1] 6\n\n\n\n\n\nYou can also make a number of logical operations. These will generally either be comparisons (is something larger than something else?) or logical operation (just like logic 101 operations like and, or, not). These operations result in a boolean value.\nComparisons are fairly straightforward. You make them with >, < and =. One thing to remember is that to test equality you need double equality sign: ==. A single = is used for assigning objects:\n\nsmall_object <- 5\nlarge_object <- 10\nsmall_object <= large_object\n\n[1] TRUE\n\nsmall_object == large_object\n\n[1] FALSE\n\n\nThere are a few things to keep in mind when making comparisons, especially of other types of objects. If you compare a true/false value to a number, R will convert the boolean to 0 or 1. If you compare strings R will start with the first letter and if they are the same it will move on to the second letter and so on. Alphabetical order determines which string is ‘larger’. Note that for some special signs (like polish signs etc) this might get weird. Another thing to note is that R is case sensitive - ‘A’ is not the same as ‘a’.\n\n'hello' < 'world'\n\n[1] TRUE\n\n\nThe other type of logical operations allow you to create more complicated comparisons. Generally & evaluates as TRUE only if both parts of the expression are TRUE. | (or) evaluates to true only if at least one part of the expression is TRUE. The last operator is the not one: !. It turns TRUE into FALSE and FALSE into TRUE.\n\nsomething_true <- TRUE\nsomething_false <- FALSE\n\nsomething_true & something_false\n\n[1] FALSE\n\nsomething_true | something_false\n\n[1] TRUE\n\n!something_true\n\n[1] FALSE\n\n\nThese operation will be especially useful when we will be filtering datasets (e.g. we want only those observations that have age higher than some value and come from a given region).\n\n\n\nOne might think that perhaps you can add strings together? Ultimately maybe something will come out of it? Lets test it out:\n\n'hello' + 'world'\n\nError in \"hello\" + \"world\": argument nieliczbowy przekazany do operatora dwuargumentowego\n\n\nYou can’t add strings together the same way you would with numbers. WWorking with strings will require some functions. We’ll dig into more details on functions in the future but for now you can think about them as operations that take some input, do something with it and produce some output. Using function generally looks like this function_name(arguments). Arguments of the functions are the inputs.\nYou can put together two strings using paste0() and cat() functions. If you want to learn more about them you can look up their documentation with ?paste0 and ?cat. Notice that cat() inserts a space between the words and paaste0 does not.\n\ncat('Hello', 'World')\n\nHello World\n\npaste0('Hello', 'World')\n\n[1] \"HelloWorld\""
  },
  {
    "objectID": "02basic_data.html",
    "href": "02basic_data.html",
    "title": "Basic data",
    "section": "",
    "text": "Now we have a very fancy calculator lets see what R can actually be more useful for. One of the most basic but at the same time useful things is the ability to save objects in R. An object can be anything with something assigned to it. You can store a number, text or whole datasets in an object. Another way to think about objects is that they are like pointers. You assign a name to an object which then points to something. Whenever you call the name of the object it refers to whatever it points to. This means that you can easily create objects and then make calculations using the objects. These calculations can then be easily reused no matter what is inside the object as long as you don’t get any errors.\n\n\nCreating an object in R is actually very simple. You just assign whatever you want to store in the object to a name you want to use to refer to your object. There are a few ways in which you can make the assignment: <-, = or sometimes ->. After creating an object it should appear in your global environment. When you want to access whatever is stored in your object you can just use the name of the object.\n\n my_first_object <- 1\n my_first_object\n\n[1] 1\n\n\n\n\n\nYou can also easily update/change an object. As a general rule in R you can’t change an object once you created it. The way to actually change it is to recreate an object by assigning a new value to the same name.\n\nmy_object <- 5\nmy_object\n\n[1] 5\n\nmy_object <- 10\nmy_object\n\n[1] 10\n\n\n\n\n\n\n\nYou can perform basic mathematical operations on objects just like you would make them on values. You can also assign such result to a new object\n\nnumber_1 <- 5\nnumber_2 <- 3\nsum_of_numbers <- number_1 + number_2\nsum_of_numbers\n\n[1] 8\n\n\nIf we now update one of the objects and repeat the same command we will get updated result.\n\nnumber_2 <- 1\nsum_of_numbers <- number_1 + number_2\nsum_of_numbers\n\n[1] 6\n\n\n\n\n\nYou can also make a number of logical operations. These will generally either be comparisons (is something larger than something else?) or logical operation (just like logic 101 operations like and, or, not). These operations result in a boolean value.\nComparisons are fairly straightforward. You make them with >, < and =. One thing to remember is that to test equality you need double equality sign: ==. A single = is used for assigning objects:\n\nsmall_object <- 5\nlarge_object <- 10\nsmall_object <= large_object\n\n[1] TRUE\n\nsmall_object == large_object\n\n[1] FALSE\n\n\nThere are a few things to keep in mind when making comparisons, especially of other types of objects. If you compare a true/false value to a number, R will convert the boolean to 0 or 1. If you compare strings R will start with the first letter and if they are the same it will move on to the second letter and so on. Alphabetical order determines which string is ‘larger’. Note that for some special signs (like polish signs etc) this might get weird. Another thing to note is that R is case sensitive - ‘A’ is not the same as ‘a’.\n\n'hello' < 'world'\n\n[1] TRUE\n\n\nThe other type of logical operations allow you to create more complicated comparisons. Generally & evaluates as TRUE only if both parts of the expression are TRUE. | (or) evaluates to true only if at least one part of the expression is TRUE. The last operator is the not one: !. It turns TRUE into FALSE and FALSE into TRUE.\n\nsomething_true <- TRUE\nsomething_false <- FALSE\n\nsomething_true & something_false\n\n[1] FALSE\n\nsomething_true | something_false\n\n[1] TRUE\n\n!something_true\n\n[1] FALSE\n\n\nThese operation will be especially useful when we will be filtering datasets (e.g. we want only those observations that have age higher than some value and come from a given region).\n\n\n\nOne might think that perhaps you can add strings together? Ultimately maybe something will come out of it? Lets test it out:\n\n'hello' + 'world'\n\nError in \"hello\" + \"world\": argument nieliczbowy przekazany do operatora dwuargumentowego\n\n\nYou can’t add strings together the same way you would with numbers. WWorking with strings will require some functions. We’ll dig into more details on functions in the future but for now you can think about them as operations that take some input, do something with it and produce some output. Using function generally looks like this function_name(arguments). Arguments of the functions are the inputs.\nYou can put together two strings using paste0() and cat() functions. If you want to learn more about them you can look up their documentation with ?paste0 and ?cat. Notice that cat() inserts a space between the words and paaste0 does not.\n\ncat('Hello', 'World')\n\nHello World\n\npaste0('Hello', 'World')\n\n[1] \"HelloWorld\"\n\n\n\n\n\n\nIf you are not sure what type of value you are working with you can use class() to check what type it is.\n\nquote <- 'Me, poor man, my library/was dukedom large enough'\nclass(quote)\n\n[1] \"character\"\n\n\nThere are situations in which you might want to change the class of the object you are working with. A common situation is when you load a dataset and a variable that should be numeric is loaded as character. It is possible to convert one type into another (but remember about the hierarchy, not everything can be converted to any other type). As a general rule all functions for converting types have the form as. so e.g. as.numeric() will convert a value to a numeric one.\n\nmessy_type <- '1'\ncorrect_type <- as.numeric(messy_type)\nclass(correct_type)\n\n[1] \"numeric\"\n\n\nHowever, be mindful that if something can’t be converted to the desired type R will try to coerce it anyway and will produce missing values (coded in R as NA).\n\nmessy_type <- 'Sweet lord, you play me false'\ncorrect_type <- as.logical(messy_type)\ncorrect_type\n\n[1] NA\n\nclass(correct_type)\n\n[1] \"logical\"\n\n\nNotice that the code above does produce an object of class logical but it stores only NA. Some other things will work however - you can convert numeric values into logical ones. 0 will be converted to FALSE and everything else into TRUE."
  },
  {
    "objectID": "03data_types.html",
    "href": "03data_types.html",
    "title": "Types of data",
    "section": "",
    "text": "So far we have worked only with single values. However, usually you want to work with whole sets of values like variables or whole datasets. There is a number of types of data you can encounter in R. A fairly easy way to orient yourself in the different types of data is:"
  },
  {
    "objectID": "04loops_conditionals.html",
    "href": "04loops_conditionals.html",
    "title": "Loops and conditionals",
    "section": "",
    "text": "Now you know how to create different kinds of objects and how to perform simple operations with them. However, very often you want to add more control over how operations are ran in R. You might want to execute a command only if a condition is satisfied. Or you might want to make the same operations for a number of elements. These are the kinds of situations for which you want to use flow control. What this refers to is basically altering how the code is executed. In a regular situations all commands from your script are executed from the first line all the way down to the last line. Flow control alters that either by specifying conditinal statements that tell R to execute a given chunk of code only if a condition is met or by using loops that repeat a given chunk of code.\n\n\nAnother way conditional statements are referred to which may be more intuitive are if else statements. They allow you to tell R to execute given chunk of code if a condition is met and to do something else if the condition is not met.\nThe general logic of conditional statements looks like this:\n\nif (condition) {\n  Do this\n  And do this\n}\n\nA single if statement can have multiple conditions chained together with | and & operators. So, for example\n\nx &lt;- 5\ny &lt;- -5\n\nif (x &gt; 0 & y &lt; 0) {\n  print(\"Hooray!\")\n}\n\n[1] \"Hooray!\"\n\n\nIn many situations you want to state what is to be done if a condition is met and what to do otherwise. This turns your statement into an if else one. The only difference is that after the if statement you add else and specify what to do then in curly brackets. With this knowledge you can already create the rules for a simple game like paper, rock, scissors!\n\n#set the choice for each player\nplayer1 &lt;- 'scissors'\nplayer2 &lt;- 'rock'\n\n#define an if statement that outputs the result of the game\nif (player1 == player2) {\n  print('draw')\n} else if ((player1 == 'scissors' & player2 == 'paper') |\n           (player1 == 'paper' & player2 == 'rock') |\n           (player1 == 'rock' & player2 == 'scissors')) {\n  print('player 1 wins')\n} else if ((player2 == 'scissors' & player1 == 'paper') |\n           (player2 == 'paper' & player1 == 'rock') |\n           (player2 == 'rock' & player1 == 'scissors')) {\n  print('player 2 wins')\n} else {\n  print('these are not allowed moves')\n}\n\n[1] \"player 2 wins\"\n\n\nTake a moment to study the code above. Notice what kinds of conditions are included in that statement. When writing an if statement it’s a good idea to consider all possible situations and how your if statement maps to them. In a paper, rock, scissors game you can have 3 outcomes: both players choose the same option (a draw), player 1 wins or player 2 wins. Notice that the code above includes also a fourth options specified in the last else statement. What if someone makes a typo and writes rook instead of rock? That last else statement safeguards us for such situations. If we didn’t include it and someone made a type then our if else statement wouldn’t produce anything. You can play around with different values of player1 and player2 to see the results.\nOne more thing about if else statements: in many situations it is a good idea to give some thought to what exactly a given statement is supposed to do and how large the statement needs to be. A good example is an if statement that is supposed to run some check (e.g. make sure that we are working with a numeric value) and stop execution if it detects a problem. Imagine a situation in which we want to do some calculations on numbers and want to make sure that we are indeed working with numeric values. you could design an if else statement that would do it:\n\nx &lt;- 'not a number'\ny &lt;- 3\nif ((class(x) != 'numeric') | (class(y) != 'numeric')) {\n  stop('This is not a number!')\n} else {\n  x + y\n}\n\nError in eval(expr, envir, enclos): This is not a number!\n\n\nTake a moment to look at the code above. Do you think it is good? It certainly gets the job done. Do you think it could be simplified?\nIn fact the else part is redundant in this case. The if statement runs the check on x and y and stops execution of the code if any of them is not numeric. If both values are numeric the execution of code simply proceeds. In this case adding an else statement makes the code harder to read (and imagine what would happen if we had to perform a number of checks like this! We would need a lot of if else statements that would make everything even less clear). The code below does the same thing as the if else statement above but is more clear.\n\nx &lt;- 'not a number'\ny &lt;- 3\nif ((class(x) != 'numeric') | (class(y) != 'numeric')) {\n  stop('This is not a number!')\n}\n## Error in eval(expr, envir, enclos): This is not a number!\nx + y\n## Error in x + y: argument nieliczbowy przekazany do operatora dwuargumentowego\n\n\n\n\nAnother way of controlling the flow of your code is by repeating a given chunk of code. There are two basic ways to do that: repeat something a number of times or keep repeating until some condition is met. The first way is called a for loop and the second one a while loop.\n\n\nBefore we make our first for loop lets take a moment to see when a for loop is not needed. Recall again that a lot of things in R are vectorized. This means that operations on vectors are conducted element-wise. Thanks to this if you want to e.g. add 5 to each value stored in a numeric vector (in the language of a for loop: for every element of a vector, add 5 to it) you can just write vector_name + 5. No need for more complicated, explicit repetition. However, there are situations in which you have to make an explicit for loop to repeat something n times. The general structure of a for loops looks like this:\n\nfor (i in object) {\n  Do this to each element\n}\n\nIt’s worth keeping in mind what the i in the for loop is. In the example above i will be every consecutive element of object. However we could do a similar thing with:\n\nfor (i in 1:length(object)) {\n  do this to object[i]\n}\n\nNow each i is a number from 1 to thew length of object and we access each element of object by using a proper (ith) index. Which way of running a for loop you choose might depend on the context. looping explicitly over elements of an object rather than indexes can be more intuitive but imagine you don’t want to do something to every element of an object but only to to a subset (e.g. from 3rd onwards). Doing it with indexes is easier. Generally the best approach is to think what you need first and code second, not the other way around.\n\n\n\nWhile loops will keep executing a given chunk of code as long as some condition is met.\nWe can use a while loop to make a very simple simulation. Lets say we want to see how temperatures change from a given temperature (lets say 20 degrees Celsius) across time and that we represent time by some random change from each previous temperature. We can create a vector with such predicted temperatures and see how long it takes for it to reach a certain level (lets say 30 degrees Celsius). We represent the change by adding a random value from a normal distribution with mean = .05 and standard deviation = .5 (this is what the rnorm(1,.05,.5) does). The while loop would look something like this. We first create the initial value and a vector to store all temperatures and next we keep adding the random value to our temperature and storing all temperatures until it reaches 30. The last line tells R to plot all the temperatures as a line plot. This is of course a very, very very simplistic simulation (temperatures don’t change in such a simple way) but it works to show you the idea behind while loops. We can then calculate e.g. how long it took for the temperature to reach a certain level.\n\nC &lt;- 20\nresults &lt;- c(20)\nwhile (C &lt; 30) {\n  C &lt;- C + rnorm(1,.05,.5)\n  results &lt;- c(results, C)\n}\n\nplot(results, type = 'line', lwd = 2, col=4, xlab = \"days\", ylab = \"temperature\")\n\nWarning in plot.xy(xy, type, ...): plot type 'line' will be truncated to first\ncharacter\n\n\n\n\n\nBecause while loops do not have a fixed number of iteration they can potentially run infinitely. This is usually not something we want so it’s a good idea to make sure that your while loop eventually stops. In case you do get stuck in an infinite loop you can press Esc in your console and this should make RStudio stop the loop by force.\nTruth is while loops are not common in R. You will rarely find yourself in situation where you need to perform some actions while a given condition is true (e.g. keep a program running until a user presses exit; keep displaying a board of a game until a player makes a move). However, it’s still good to know what while loops are so that you will know one when you see it.\n\n\n\n\nThere is a special family of functions in R that makes working with for loops a bit easier. These functions let you specify what to loop over and what function to apply to each element but in a function rather than a whole loop with all the curly brackets and stuff.\nThe reason why this is a whole family of functions is that you can iterate in various ways and you can get the output in different formats. There are more functions in the family but the general ones are:\n\nlapply() - loops over elements of a vector/list and returns a list\nsapply() - same as lapply but tries to simplify the result to a vector or matrix\napply() - used for looping over 2 dimensional structures - it lets you specify if you want to loop over rows or columns\ntapply() - same as apply but lets you split the object you are looping over based on some factor (e.g. imagine you want to calculate the mean value of your dependent variable for each experimental condition).\n\nLets see some of these in action.\nExample 1:\nImagine you are working with a list in R. You want to get information on how many elements each object in the list has. sapply makes it very easy:\n\nmy_list &lt;- list(\n  1:50,\n  sample(300, 5),\n  c(\"random\", \"vector\")\n)\n\nsapply(my_list, length)\n\n[1] 50  5  2\n\n\nExample 2:\nThere is a dataset available in R on airquality in New York City called airquality. It stores information on ozone, sun, wind and temperature from 5 months One of the things that might be of interest when looking at the dataset is what was the average value of each of the variables informing on airquality:\n\ndata(\"airquality\")\nd &lt;- airquality\nd &lt;- na.omit(d)\napply(d[,1:4], 2, mean)\n\n    Ozone   Solar.R      Wind      Temp \n 42.09910 184.80180   9.93964  77.79279 \n\n\nNotice that the means calculated above are global means from the entire dataset. What is probably much more sensible is a mean for each month. There is one additional trick needed here. Tapply won’t allow us to split a number of columns by some vector and perform a given operation on each of the columns. That’s because tapply works on vectors. In order to get monthly means for all 4 columns we need to combine apply with tapply. What we need to do is start with apply and loop over the 4 columns of interest and for each of them use tapply that will split a given column by month and calculate the means. Combining functions can get us really far if only we give some thought to what each function does (including what are its inputs and outputs) and what we really need to do.\n\napply(d[,1:4], 2, function(x) tapply(x, d$Month, mean))\n\n     Ozone  Solar.R      Wind     Temp\n5 24.12500 182.0417 11.504167 66.45833\n6 29.44444 184.2222 12.177778 78.22222\n7 59.11538 216.4231  8.523077 83.88462\n8 60.00000 173.0870  8.860870 83.69565\n9 31.44828 168.2069 10.075862 76.89655\n\n\n\n\n\n\nTry to code the logic of assigning points to players of a prisoner dilemma with a given matrix:\n\nCreate a for loop that will print out the first 50 numbers from the Fibonacci sequence\nGiven the iris dataframe (you can load it with data(\"iris\") loop over all of its columns and calculate the mean of every numeric column"
  },
  {
    "objectID": "05functions.html",
    "href": "05functions.html",
    "title": "Functions",
    "section": "",
    "text": "Most of the things we do in R doesn’t have to be written from scratch. We have many tools available to get what we want. These tools are functions.\n\n\nThe first approximation to how a function is built is to think of it as a kind of machine. The machine takes some inputs, processes them in some way and returns outputs. The inputs are the arguments you provide to a function like a vector or a dataset. The result is the output. Very often the insides of a function, the machinery within it that is responsible for getting from the input to the output is a black box to us. We have no clue how exactly a function arrives at its result. Sometimes we don’t need to know it but in many situations at least some knowledge is necessary to be certain that the function does exactly what we need it to do and won’t surprise us (an annoying example we will get to later is silent dropping of missing values by some functions).\n\n\n\nLets focus on the inputs. There are a few kinds of them. The most basic ones are input arguments - this is what you put into the machine. Apart from it there are a few other types of arguments that can allow you to have more control over the behavior of functions. They are a bit like toggles and switches on a machine that change how it operates.\nDefault arguments: arguments that are set to some default value. This value will be used unless specified otherwise. An example is the na.rm argument from mean or sum. This argument is set to FALSE by default so that the function will return an error if there are any missing values in the input argument. This is such a good example because it also stresses why choosing proper defaults is really important when writing functions. A lot of people, when they first encounter functions like mean or sum, are surprised or even annoyed. Why in the world set defaults that are more likely to produce errors? We are often fixated on avoiding errors in code but this is not always the way to go in data analysis. We often want functions to operate smoothly and seamlessly. But that is false peace. Smooth behavior is not always what we need from functions. Clunky functions are often good in data analysis because they force us to be explicit with what we do with data. Even if they make climbing the hill a bit more steep they are sure to lead us on the right path to the top.\nYou can also encounter alternative arguments. These arguments have a prespecified set of possible values (usually defined as a vector).= For example the table() function that can give us a frequency table of a factor has a useNA argument that specifies whether to use NA values.It can take three different valus that specify possible behaviour of the function. You can read more onwhat they do inthe documentation of the function.\nThe final type of argument is the … argument. It is a placeholder for any number and kind of arguments that will later on be passed inside the function usually as arguments in some internal function. Take lapply as an example. Apart from the argument X and FUN which specify what to loop over and what function to apply to each element of X it also has the … argument. It’s there because the function you want to apply to every element of X might take some additional arguments. How many and what kind of arguments these are might vary from function to function and the … argument allows us to handle this. Any arguments passed in the … will be used as argument of the function specified in the FUN argument of lapply.\n\n\n\nWhy spend time building your own functions? There are a few general cases. The first and probably most obvious one is when there is no available function that would do what you need. For example there is no available function to find a mode of a vector in R. If you want to find it you need to build your own function. Finding a mode is a simple example but there may be cases where you need to do something more complex or customize the behavior of an already existing function. Second reason is to avoid repetition. If you do similar operations a number of times (e.g. only the dataset or vriables change but all the rest stays the same) then copying and pasting code will soon become problematic. It makes code less readable, longer and more difficult to manage. Imagine you need to change one thing in that code. You’ll need to change it in every place where it was pasted. Writing a function instead means you can just change how you define the function.\nThe general logic for defining a function is as follows:\n\nmy_function &lt;- function(arguments) {\n  #what the function does\n}\n\nTurning a chunk of code into a function can be done quite easily in a few steps. Imagine we want to see what is the probability that a random number drawn from one vector will be larger than the mean of another vector (we will simulate a few variables with rnorm() which draws random numbers from a normal distribution with a given mean and standard deviation):\n\n#simulate vectors\nvar1 &lt;-rnorm(100, 0, 1)\nvar2 &lt;- rnorm(100, 1, 3)\nvar3 &lt;- rnorm(100, .5, 2)\nvar4 &lt;- rnorm(100, 0, 3)\nvar5 &lt;- rnorm(100, 0.1, .2)\n\n#calculate mean\nmean_1 &lt;- mean(var1)\n\n#calculate lenght\nlength_2 &lt;- length(var2)\n\n#calculate how many values in var2 are larger than mean_1\n\nn_larger &lt;- length(var2[var2 &gt; mean_1])\n\n#get the proportion\n\nn_larger/length_2\n\n[1] 0.57\n\n\n\nBuild the scaffolding of the function. This is exactly what is in the code chunk above:\n\nmy_function &lt;- function(arguments) {\n  #what the function does\n}\n\nPaste the code you want to turn into a function\n\nmy_function &lt;- function(arguments) {\n#calculate mean\nmean_1 &lt;- mean(var1)\n\n#calculate lenght\nlength_2 &lt;- length(var2)\n\n#calculate how many values in var2 are larger than mean_1\n\nn_larger &lt;- length(var2[var2 &gt; mean_1])\n\n#get the proportion\n\nn_larger/length_2\n}\n\nIdentify all the “moving parts”: What will change? Each of these things has to get its own argument (all the moving parts are marked on the right side of the code chunk):\n\nmy_function &lt;- function(arguments) {\n#calculate mean\n1mean_1 &lt;- mean(var1)\n\n#calculate lenght\n2length_2 &lt;- length(var2)\n\n#calculate how many values in var2 are larger than mean_1\n\n3n_larger &lt;- length(var2[var2 &gt; mean_1])\n\n#get the proportion\n\nn_larger/length_2\n}\n\n\n1\n\nvar_1\n\n2\n\nvar_2\n\n3\n\nvar_2\n\n\n\n\nChange each of the “moving parts” in the code chunk into appropriate argument\n\nmy_function &lt;- function(x, y) {\n#calculate mean\nmean_1 &lt;- mean(y)\n\n#calculate lenght\nlength_2 &lt;- length(x)\n\n#calculate how many values in var2 are larger than mean_1\n\nn_larger &lt;- length(x[x &gt; mean_2])\n\n#get the proportion\n\nn_larger/length_2\n}\n\n\n\n\nWhen building your own functions, especially if they are going to be used by other people, it’s a good idea to consider potential weird things that could happen. When first creating a function we usually have its typical behaviour in mind because we just want our function to work. However, there’s a whole bunch of weird stuff that might happen if you don’t prepare for it in advance. For example, imagine you want to create a function from scratch that will output the mean of a numeric vector. You could try to do something like a for loop (yes this is slow and inefficient but it’s just for the purpose of demonstration):\n\nmy_mean &lt;- function(x) {\n  sum &lt;- 0\n  for(i in x){\n    sum &lt;- sum + i\n  }\n  result &lt;- sum/length(x)\n  return(result)\n}\n\nPretty straightforward right? Now lets see our function in action on some typical use case and compare its results to the built-in mean() function:\n\nv &lt;- c(1,2,3,4,5,6,7,8,9)\n\nmy_mean(v)\n\n[1] 5\n\nmean(v)\n\n[1] 5\n\n\nYay, we get the same result! Seems like our function works! But before we call it a day and start using our own mean function lets see some less typical cases. E.g. What will happen if the vector has some missing values? Or if its an empty vector? Or if it is not a numeric vector? Lets see:\n\nv_na &lt;- c(1,2,3,NA,5)\nv_empty &lt;- c()\nv_char &lt;- c(\"A\", \"B\", \"C\")\n\nmy_mean(v_na)\n\n[1] NA\n\nmy_mean(v_empty)\n\n[1] NaN\n\nmy_mean(v_char)\n\nError in sum + i: argument nieliczbowy przekazany do operatora dwuargumentowego\n\n\nWe get some weird behaviour. Each of these calls to my_mean() function returned something different. First we got NA when the vector had NAs in it. Passing an empty vector resulted in NaN - short for Not a Number. Finally, passing a character vector gave us an error.. Notice that only the last case gave us an error so if we then implemented our functions in some calculations we might not even notice something is wrong - for example imagine we calculated a mean with our function from a vector with missiing values (e.g we asked a bunch of participants about their mood 5 times a day and now we want to calculate daily average mood and see how it relates to some variables of interest) and then tried to use its output in some other function that had na.rm argument set to TRUE. We’d lose a bunch of information without so much as a warning! That`s why considering possible but unusual cases for a new function is important. It allows us to prepare for possible future problems.\n\n\n\n\nThere are situations in which you might want to use a custom function but not necessarily save it with a name for future use. In such situations we often use what is called an anonymous function (sometimes you can also encounter the term lambda functions). The general way these functions are constructed in R is as follows:\n\n(function(x) WHAT THE FUCNTION DOES)(arguments)\n\nA pretty common situation where you can also encounter these functions is inside iterations like with apply:\n\nv1 &lt;- c(1,2,3,4)\nv2 &lt;- c(3,4,5,6,8)\nv3 &lt;- c(-1,4,3,2)\nv_list &lt;- list(v1,v2,v3)\n\nlapply(v_list, function(x) {x+x})\n\n[[1]]\n[1] 2 4 6 8\n\n[[2]]\n[1]  6  8 10 12 16\n\n[[3]]\n[1] -2  8  6  4\n\n\n\n\n\nOk, so we wrote our super cool new function. We tested it and are pretty confident it works properly. Can we finally call it a day? Again, not so fast. We need one more thing. Imagine you take a long holiday and get back towork after a month or two, How confident are you you will remember how exactly our new function works? Or imagine you share the function you ccreated with other people .Of course you (or others) can read the code of the function to learn that again but that is tedious. That`s why it’s so important to document code. This goes for functions but is just as true for any code that will be used by others or you in the future. Treat yourself in the future like you would treat another person. Documentation is super important! For a lot of people writing (or reading!) documentation is seen as tedious and redundant task. I guarantee you that if you don’t document your own functions you will regret this sooner or later (probably sooner). Very few functions are self explanatory enough to not need any form of documentation. In many cases simply using comments in code with # will be enough. Sometimes building vignettes that shows how to use some functions can be a better idea. Remember to always leave some description of what given code is about and what it does.\n\n\n\nSince R has a huge community people are constantly developing new things you can do in R. You don’t have to define everything from scratch. Usually if you need a function for some statistical procedure or e.g. for plotting some package out there already has it. There is no need to reinvent the wheel.\nIn order to use functions from packages you need to first install the package on your computer. You can do it by calling install.packages(\"PACKAGENAME\") functon. You need to do it only once on a given device (unless you want to update the package or you are using renv but more on that later). Once the package has been installed you can load it in a given R session by calling library(PACKAGENAME). Remember you need to run it every time you open a new R session. Alternatively, after installing a package you can call a function from it directly without loading the package first by using PACKAGENAME::function_name().\nAnother thing to know about functions from packages is name conflict. Since R is open source and most of the packages are developed and maintained by the community it is not so uncommon that two different packages have a function with the same name. You might wonder what will happen if you load both packages and then call this function? Generally, the last package loaded is going to mask previous packages. However this can be problematic e.g. if you are sharing scripts (and someone changes the order of loading packages) or if you actually want to use the function from the first package.\nThere are at least two ways of dealing with this problem. The first one is to be explicit. Above we described a second way of calling a function from a package: PACKAGENAME::function_name(). This way you explicitly state which package the function is from so you shield yourself from name conflict. The second way is by specifying additional arguments to the library() function. If you look up its documentation you can see that it has two optional arguments: exlcude and include.only. They allow you to load a package without some function or to load only some functions from a package. This is useful in situations where you want to load 2 packages with conflicting functions but you know you want to use the conflicting function from only one of them.\n\n\n\n\nRemember the for loop that generated n first numbers from Fibonacci sequence from the class on loops? Now turn it into a function that will return from ith to jth Fibonacci number. Document the function properly so it is clear what it does\nCreate a function that calculates a mode of a vector. Consider potential edge cases and provide tests that show your function behaves properly"
  },
  {
    "objectID": "06loading_data.html",
    "href": "06loading_data.html",
    "title": "loading_data",
    "section": "",
    "text": "There are many ways of loading a dataset or file into your R session so that you can use it. How to do it depends mainly on how the data is stored.\nWhen loading a dataset there are generally a few things to consider."
  },
  {
    "objectID": "06loading_data.html#loading-flat-files",
    "href": "06loading_data.html#loading-flat-files",
    "title": "loading_data",
    "section": "Loading flat files",
    "text": "Loading flat files\nWe’ll start with loading what are called flat files: csv (short for comma separated values) and tsv (tab separated values). Both of these are basically plain text files just structures in a ver specific wayThe name kind of gives away how these formats store data: in csv columns are separated by commas and in tsv columns are separated by tabs. You can see an example of a csv file below:\nPut screenshot of csv file here\n\nHow to load csv and tsv files\n\nutils\nreadr\ncustom arguments. There’s a bunch of things we can customize when loading data into R. Maybe you don’t need the entire dataset but only a subset of columns? Or you want to manually specify what types of variables you want? Or maybe the dataset you are using does not have variable names? You can specify all of these things as arguments to the loading functions."
  },
  {
    "objectID": "06loading_data.html#loading-data-from-spss",
    "href": "06loading_data.html#loading-data-from-spss",
    "title": "loading_data",
    "section": "Loading data from SPSS",
    "text": "Loading data from SPSS\nData coming from statistical software can’t be loaded in such a simple way as above. Mainly because it stores more information. Here we’ll focus on .sav format which is used by SPSS. Apart from rows and columns (observations and variables) .sav format stores additional information e.g. on value labels - it is able to attach labels to numbers (like in Likert scales 1 can refer to ‘strongly disagree’). SPSS also allows to specify user-defined missing values (a common practice is to e.g. code missing values with 99).\nThis means we have to somehow deal with this additional information when loading .sav files. There are essentially two ways to go about it: reduce the amount of information stored or introduce a new type of values that can store this additional information. This first approach is taken by the foreign package. The second one is taken by haven package. Each of these approaches has some advantages and drawbacks. Stripping labels from values is generally easier and keeps consistency in terms of types of objects you are dealing with. You just keep working with numeric, integer, character or boolean values. The downside is that you lose some information and when e.g. saving a data file back to .sav format you can’t restore them.\nDiscuss the consequences: you keep types of values native to R but loose information or you introduce a new format of data that keeps the information but might not work with some types of analysis\n\nloading data with foreign\nGo through loading data in foreign\nPlease notice though that the documentation for read.spss() function in foreign states that it was originally developed in 2000 and does not guarantee compatibility with newer versions of SPSS (whcih hasn’t changed much since but still).\nBy default foregin will load data into a list rather than a dataframe. You can load into a data frame by setting the argument to.data.frame to TRUE. Another useful argument is use.value.labels which, if set to TRUE will convert the numerical values stored in .sav into their corresponding labels. This is the way foreign deals with labelled values: you can use either numeric values or their labels. In the documentation of the function you can read about additional arguments that control handling of labels.\n\nlibrary(foreign)\n\nOnce we have the data loaded lets see what types of values we have.\n\n\nloading data with haven\nHaven package deals differently with loading labeled variables. It introduces a new type of variable: haven-labelled data. It is capable of storing both numeric values and labels attached to it by adding an attribute to the variable with labels.loops_conditionals\n\nlibrary(haven)\n\nNow that we have loaded the dataset, lets look at the types of variables we have"
  },
  {
    "objectID": "06loading_data.html#loading-excel-files",
    "href": "06loading_data.html#loading-excel-files",
    "title": "loading_data",
    "section": "Loading excel files",
    "text": "Loading excel files\nOne additional thing you have to take into account when loading data from excel is that it can store a number of sheets in a single file. This has to be taken into account when loading such file into R.\nOne of the packages available for loading excel data is readxl.\n\nlibrary(readxl)"
  },
  {
    "objectID": "06loading_data.html#loading-jsons",
    "href": "06loading_data.html#loading-jsons",
    "title": "loading_data",
    "section": "Loading jsons",
    "text": "Loading jsons\nThere are situations in which you might work with data that does not come from simple tables but is stored in completely different way. One example that we’ll introduce here is the json format. Json is short for Javascript Object Notation and is a common way of storing data in the web.\nJson stores data as key - value pairs. These might not approximate tabular format and can be nested and fairly complicated. This type of data is especially common when downloading data directly from the web (e.g. social media data) or from APIs. You can imagine a file that stores information on each user of a website: their username, password and all posts that they have created along with information on each post like their creation date. It might look something like this:\nPut an image of a json file here\nBecause json can be a complicated and nested structure the type of data that best approximates it in R is a list. There are ways to ask R to try and handle such list structure and try to convert it into a data frame but it does not always work. Cleaning an unevenly nested json can be a real pain sometimes!\nWe’ll look at an example of a NASA API that stores information on the number of people currently present on space stations. The package we’ll use to load the data is jsonlite.\nNotice how the loaded object looks like. It is a list with …"
  },
  {
    "objectID": "07data_wrangling.html",
    "href": "07data_wrangling.html",
    "title": "data wrangling",
    "section": "",
    "text": "Now that we have our dataset loaded we can finally get to work with it!\n\n\nWe’ll be working within Tidyverse throughout this course.\n-Explain what tidyverse is\n-How each package functions within tidyverse\nFor now we’ll focus on dplyr.\n\n\n\n-What is the pipe, why it’s useful\n-Native pipe alternative\n\n\n\n-Filter\n-Select\n-Mutate\n-Summarise\n-Group by\n-Arrange\n\n\n\n-Chaining functions together with pipes\nThis already gives us the ability to anwser a number of questions that might be very interesting for analysis.\n\n\n\n-make this section optional: if you want to see how to achieve similar things but without using tiduverse"
  },
  {
    "objectID": "08join_restructure.html",
    "href": "08join_restructure.html",
    "title": "restructuring_and_joining_data",
    "section": "",
    "text": "-separating and uniting variables\n-separate when there is various number of values\n\n\n-Different types of joins\n-Gotchas in joins\n\n\n\n-pivot longer\n-pivot wider"
  },
  {
    "objectID": "09data_viz_1.html",
    "href": "09data_viz_1.html",
    "title": "Data visualization part 1",
    "section": "",
    "text": "R is absolutely great for plotting\n\n\n-Describe ggplot2 - part of tidyverse.\nOne of the great things about it is that it breaks down each plot into a number of layers that can be changed (more or less) independently.\n\n\n\n-What is grammar of graphics\n-What layers are there in ggplot2\n-ggplot() starts the plot and each layer is chained together with a +.\n\n\n\n-What are aesthetics\n-What are the basic aesthetics\n\n\n\nAfter providing a dataset and aesthetics we have the variables and their mapping to axes on the plot. However, we still don’t have any shapes to actually represent the data. Do we want a scatter plot? Or maybe a bar plot? Or a line plot? The shapes used to represent the data are defined in the geometry layer. Generally all geometries start with geom_ so for example geom_point() will make a scatter plot while geom_bar() will make a bar plot.\nGeometries differ in what aesthetics they accept. You can look up what these are by looking up help for a given geometry. They also differ in what kinds of variables they expect (any combination of categorical vs continuous variables)\n-What are some common geometries:\nNow we can make our first plot in ggplot!\n\nlibrary(ggplot2)\n\nWarning: pakiet 'ggplot2' został zbudowany w wersji R 4.2.2\n\n\nThere is one more thing about geometries and aesthetics. You can set global aesthetics inside the ggplot() function. If you do so these aesthetics will be used by default by all geometries in that plot. You can also set aesthetics inside a given geometry (in fact you can even set a different dataset for a given geometry; this is what we meant by independence of layers) but then they will be used only for this particular geometry and won’t be inherited by other ones.\nCompare the to plots below. They produce the same result:\n\n\n\nAnd the second plot:\n\n\n\n\n\n\nThere are situations in which you don’t want to set some feature to be represented by a given variable but to set them to a fixed value for the entire plot/geometry. For example you might want to set the color or size of all points in a scatter plot. That’s when you set attributes. They are declared inside geometries but outside of aesthetics.\n\n\n\nOne more thing are functions for working with scales: they allow you to have more control over how each scale is represented (e.g. what the breaks and values are, should the scale be transformed)\n\n\n\nA cautionary tale about the limits: scale functions allow you to\n\n\n\nScale functions also allow you to control the color and fill aesthetics.\n\nDiscuss brewer and viridis packages\n\nWhat to be mindful of when setting color palettes:\n\nhow people perceive color\nwhat information you want to represent (is there some order to the variable, is it divergent etc.)"
  },
  {
    "objectID": "10data_viz_2.html",
    "href": "10data_viz_2.html",
    "title": "Data visualization part 2",
    "section": "",
    "text": "We know how to make various plots to display the data and how to control the attributes and scales. Now we’ll move on to additional layers in ggplot2\n\n\nThere are situations in which there is too much information to put it in a single plot.\n\n\n\n\nhow to represent statistics on a plot\nPre-calculating values\nstat_summary\n\n\n\n\nThis layer controls how the coordinates of the plot should be handled. Most likely you are used to plots with the cartesian space: an x and y axis that are perpendicular. However you can change that e.g. by fising the ratio of x to y axis, zooming in on a particualr part of the plot or even bending the axis altogether.\n\n\n\nThe final layer, called theme, controlls all the non-data part of the plot: setting fonts, typeface, text size, controlling the background color, plot legend and the grid.\nThere is a number of pre-specified themes that you can use but you can also control everything manually. You can check the documentation of theme() to see just how many elements you can control.\n\nsome example themes\ncontrolling theme yourself\n\n\n\nA note on working with fonts: if you want to work with more fonts than the built-in ones you will have to load them into R. This can sometimes prove quite problematic.\n\nshowtext package"
  },
  {
    "objectID": "11organizingwork.html",
    "href": "11organizingwork.html",
    "title": "Organizing your work",
    "section": "",
    "text": "Organizing your work:"
  },
  {
    "objectID": "11organizingwork.html#working-directories",
    "href": "11organizingwork.html#working-directories",
    "title": "Organizing your work",
    "section": "Working directories",
    "text": "Working directories"
  },
  {
    "objectID": "11organizingwork.html#environments",
    "href": "11organizingwork.html#environments",
    "title": "Organizing your work",
    "section": "Environments",
    "text": "Environments"
  },
  {
    "objectID": "11organizingwork.html#projects",
    "href": "11organizingwork.html#projects",
    "title": "Organizing your work",
    "section": "Projects",
    "text": "Projects\n-what is a project\n-why is a project useful"
  },
  {
    "objectID": "11organizingwork.html#renv",
    "href": "11organizingwork.html#renv",
    "title": "Organizing your work",
    "section": "Renv",
    "text": "Renv\n-managing package versions\n-groundhog package"
  },
  {
    "objectID": "11organizingwork.html#rprofile",
    "href": "11organizingwork.html#rprofile",
    "title": "Organizing your work",
    "section": ".Rprofile",
    "text": ".Rprofile\n-what these are and why they might be useful"
  },
  {
    "objectID": "12eda.html",
    "href": "12eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Some introduction on moving on to section about data analysis.\nExploring and cleaning data is often a necessary and fairly long process\nWhy even bother with it?\nIt is a necessary steps because there is a near-infinite number of things that can go wrong when preparing the data from errors in how data was coded to errors in preprocessing or loading the files. Lots of things can also happen that can make analysis or drawing conclusions difficult (like how reliable are your scales, are the items recoded correctly etc.)"
  },
  {
    "objectID": "12eda.html#getting-the-basic-information-about-a-dataset",
    "href": "12eda.html#getting-the-basic-information-about-a-dataset",
    "title": "Exploratory Data Analysis",
    "section": "getting the basic information about a dataset",
    "text": "getting the basic information about a dataset\n\nif you have it, start with any documentation on the dataset (like codebooks etc.)\nGetting basic info on the data: glimpse etc.\nDescribe from psych package\nGetting information on categorical variables"
  },
  {
    "objectID": "12eda.html#exploring-via-plots",
    "href": "12eda.html#exploring-via-plots",
    "title": "Exploratory Data Analysis",
    "section": "Exploring via plots",
    "text": "Exploring via plots\nWhy plotting data is always important\nA cautionary tale the boring way: Anscombe quartet\nThe fun way: Gorilla in the data\nThe key takeaway is that a lot of things that are wrong or at least problematic can be immediately spotted when you plot the data. e.g. in when comparing two conditions of an experiment you might spot that the whole effect is driven but just a few outliers."
  },
  {
    "objectID": "12eda.html#reliabilities",
    "href": "12eda.html#reliabilities",
    "title": "Exploratory Data Analysis",
    "section": "reliabilities",
    "text": "reliabilities\n-getting reliability analysis with alpha()"
  },
  {
    "objectID": "14anova.html",
    "href": "14anova.html",
    "title": "Anova",
    "section": "",
    "text": "-many groups, many means\n\n\n-how to make a one-way anova.\n\n\n-What these are and how to make them\n\n\n\n-How these are different from post hocs\n-How to make them\n\n\n\n\n\n\n\n-how to interpret the results\n-plotting results\n-effect size and power"
  },
  {
    "objectID": "15correlations.html",
    "href": "15correlations.html",
    "title": "correlations",
    "section": "",
    "text": "-what are those"
  },
  {
    "objectID": "16regression.html",
    "href": "16regression.html",
    "title": "Regression",
    "section": "",
    "text": "What type of problems are we talking about?\n-What is a regression analysis?\n\n\nRegression analysis is often described in two ways. One of them talks about how to predict a value of variable of interest given a set of other variables. The other context focuses on inference: which variables are in fact related to a variable of interest.\nHousing market example: imagine you work in a real estate agency selling houses. You track information on a number of characteristics of each house: their price, size, number of rooms, distance from city center and various facilities etc. You might be interested in predicting the price of a house as accurately as possible given all the characteristics of a house. You might also be interested in how various characteristics of a house relate to its price so as to know what to focus on.\n\n\n\nThe very idea of making a regression analysis is ultimately an optimization problem. We want to reexpress the relations between variables so as to be able to express one of them as a combination of the other ones.\nMaking a guess:\nSo, we know we need to optimize our prediction - we want to make the best guess possible. But what does it mean ‘the best guess possible’? We need some rule on what it would mean to make a best guess. Since we are predicting a continuous variable we can calculate how much we miss for every prediction (subtract the actual value from the predicted value) and then choose the one that has the smallest error. This is already a start but we can miss in two ways: we can predict too little or too much. The first one is going to produce a negative error and the other one a positive one. Negative numbers are smaller than positive ones so our rule so far will always favor predicting too little! Fortunately there is a very easy way to deal with this - we can square the errors (there are reasons why squaring is preferred to taking absolute values but they are beyond the scope of this course). Now, we can sum all the squared errors for each observation in our dataset. The prediction that gets the smallest sum of squared errors wins! This is pretty much how the Ordinary Least Squares (OLS) regression works.\nLets start with the simplest example possible. Lets say we have no other information except our variable that we want to predict. Which value will minimize the sum of squared errors? There’s actually a fancy formula for this because OLS regression has a closed form but perhaps a better way to learn this is to actually make a bunch of guesses and see what happens. This is what simulation is perfect for.\nLets first simulate a bunch of observations from a normal distribution: our dependent variable. We will keep mean = 0 and standard deviation = 1.\n\ny <- rnorm(1000)\n\nNext, we’ll make a bunch of guesses and see how each of them performs (what is their sum of squared errors)\n\nsse <- c() #initialize vector to store sum of squared errors\npred <- seq(-1,1,length.out = 10) #we'll make 10 guesses from -1 to 1, equally spaced\nfor (i in pred) {\n  res <- sum((i - y)^2) # for each guess calculate sum of squared errors\n  sse <- c(sse, res) #append the sum to the vector\n}\npred_sse <-data.frame(pred,sse) #put these \n\nYou can go ahead and inspect the sse and pred. Can you see for which guess we get the smallest error? You can also look at the animation below:\n\n\n\npredictions and sums of squared errors\n\n\nYou can see that the points fall on a really nice parabola. For a guess of mean - 1 standard deviation we get a really big sum of squared errors, they gradually get smaller and smaller and then start to get bigger up to mean + 1 standard deviation. The lowest point of the parabola is at the mean and that is in fact our best guess. When making regression analysis we will be working with means all the time. We’ll just be adding more information to the model (e.g. if we add belonging to experimental vs control group into the model, then our best guess will be the mean in each of those groups and we get a two sample t-test).\nA more general way which we can use to think about linear models is that we are modelling Y as following a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma\\). The mean is then determined by the variables we put into the model. If we don’t add anything \\(\\mu\\) is going to be the actual mean in our sample. If we start adding variables into the model then \\(\\mu_i\\) will be determined by them (that’s why we have the i).\n\\[\nY_i \\sim Normal(\\mu_i, \\sigma)\n\\\\\n\\mu_i =\\alpha\n\\]\n\n\n\n-how to make a regression analysis\n-how to look at the results\n\n\n\n-how to make it\n-Why you should always think first: putting things into regression"
  },
  {
    "objectID": "13t-tests.html",
    "href": "13t-tests.html",
    "title": "t tests",
    "section": "",
    "text": "-The whole idea behind the t-tests.\nThe logic behind a t test."
  },
  {
    "objectID": "03data_types.html#vectors",
    "href": "03data_types.html#vectors",
    "title": "Types of data",
    "section": "Vectors",
    "text": "Vectors\nThe most basic type of data is a vector. Vectors can store any number of values of the same type in 1 dimension. You can create a vector using c() function.\n\nmy_very_first_vector <- c(1,2,3)\nmy_very_first_vector\n\n[1] 1 2 3\n\n\nVectors are indexed: they have a first, second value etc. This means that you can access part of a vector -subset them. Subsetting is accomplished with []. You can also subset a range of values from a vector wirh [:].\n\nlong_vector <- c(1,2,3,4,5,6,7,8,9,10)\nlong_vector[3:5]\n\n[1] 3 4 5\n\n\nIf you try to put different types of values into one vector R will convert the types to a matching one. This is especially important when due to some mistake/error a single value of a different type gets lost in some other variable. Just a single value will trigger the whole variable to be converted.\n\nmy_vector <- c(1, TRUE, 'some text')\nmy_vector\n\n[1] \"1\"         \"TRUE\"      \"some text\"\n\nclass(my_vector)\n\n[1] \"character\"\n\n\nYou can make pretty much the same operations on vectors as on single values. One of the great features of R is that by default it will make operations element wise - if you try to add two vectors together then the first element from vector 1 will be added to first element of vector 2 and so on (the fancy name for this is vectorization).\n\nnumbers <- c(1,2,3,4,5)\nnumbers2 <- c(6,7,8,9,10)\nnumbers + numbers2\n\n[1]  7  9 11 13 15\n\n\nIf the vectors have different lengths then R will start to recycle values from the shorter vectors. But it will output a warning if the length of one vector is not a multiple of the other vector.\n\nshort_v <- c(1,2,3)\nlong_v <- c(1,2,3,4,5)\nshort_v + long_v\n\nWarning in short_v + long_v: długość dłuszego obiektu nie jest wielokrotnością\ndługości krótszego obiektu\n\n\n[1] 2 4 6 5 7"
  },
  {
    "objectID": "03data_types.html#factors",
    "href": "03data_types.html#factors",
    "title": "Types of data",
    "section": "Factors",
    "text": "Factors\nFactors are much like vectors except that they are used for storing categorical values - they have levels. You can store variables such as country or experimental condition of participants in a factor. You can create a factor by calling factor() and passing it a vector as an argument.\n\nmy_vector <- c('a', 'b', 'a', 'b')\nmy_factor <- factor(my_vector)\nmy_factor\n\n[1] a b a b\nLevels: a b\n\n\nFactors can also have ordered levels. You can make an ordered factor by setting ordered = T argument when creating a factor. Notice how the output looks different now: it includes information on the order.\n\nordered_vec <- c('low', 'high', 'high', 'low', 'low')\nordered_fac <- factor(ordered_vec, ordered = T)\nordered_fac\n\n[1] low  high high low  low \nLevels: high < low\n\n\nYou can also manually set the levels of a factor. You can do it when creating the factor. Notice that for ordered factor the order in which you pass the levels will determine the order of levels in the factor.\n\nordered_vec <- c('low', 'high', 'high', 'low', 'low')\nordered_fac <- factor(ordered_vec, ordered = T, levels = c('low', 'high', 'medium'))\nordered_fac\n\n[1] low  high high low  low \nLevels: low < high < medium"
  },
  {
    "objectID": "03data_types.html#matrices",
    "href": "03data_types.html#matrices",
    "title": "Types of data",
    "section": "Matrices",
    "text": "Matrices\nMatrices are a bit like vectors but they have two dimensions. They have rows and columns but treat them in the same way. Because of this they can store only one type of values (much like vectors). You can create a matrix from scratch with the matrix() function. This function takes a vectors of values as its input (these are the values we will fill our matrix with) and additional information on how the matrix has to look - how many columns and rows it should have and whether to fill the matrix with values by rows or columns\n\nnumbered_vector <- c(1,2,3,4,5,6,7,8,9)\nmy_matrix <- matrix(numbered_vector, nrow = 3, ncol = 3)\nmy_matrix\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\nYou can also create a matrix by ‘glueing’ vectors together. You can bind them either as rows (rbind() function) or by columns (cbind() function). Notice that the names of the vectors will be used either as names of rows or columns.\n\nvec1 <- c(1,2,3)\nvec2 <- c(4,5,6)\ncbind(vec1, vec2)\n\n     vec1 vec2\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n\nSince we have two dimensions subsetting matrices can work both on rows and columns. The general idea is still the same but we have to specify whether we are subsetting rows or columns. Rows always come first, columns second separated by a comma like this matrix[rows,columns]. You can select ranges of rows or columns just like in a vector.\n\nmy_matrix[2,2]\n\n[1] 5\n\n\nIf you want to select all rows or columns you can leave the space blank. Remember to keep the comma though!\n\nmy_matrix[,3]\n\n[1] 7 8 9"
  },
  {
    "objectID": "03data_types.html#data-frames",
    "href": "03data_types.html#data-frames",
    "title": "Types of data",
    "section": "Data frames",
    "text": "Data frames\nIn a day to day analysis you will likely work with data frames most of the time. A data frame is like a matrix in that it has rows and columns but can store different types of values in each column (so that e.g. you can have some variables that are numeric and others that are text). A different way of thinking about data frames is as a list of vectors of the same length with each vector representing a different variable. Each row represents a different observation (e.g. participant).\nYou can create a data frame with data.frame() function passing all the variables as arguments. Lets create 3 vectors: author, title and year.\n\nauthor <- c('Allport', 'Heider', 'Lewin', 'Allport', 'Heider')\ntitle <- c('Nature of Prejudice', 'Psychology of interpersonal relations',\n           'Principles of Topological Psychology', 'Psychology of Rumor', 'The life of a psychologist: An autobiography')\nyear <- c(1954, 1958, 1936, 1947, 1983)\n\npsych_books <- data.frame(author, title, year)\npsych_books\n\n   author                                        title year\n1 Allport                          Nature of Prejudice 1954\n2  Heider        Psychology of interpersonal relations 1958\n3   Lewin         Principles of Topological Psychology 1936\n4 Allport                          Psychology of Rumor 1947\n5  Heider The life of a psychologist: An autobiography 1983\n\n\nSubsetting data frames works the same way as matrices. You can subset both on rows and columns. An important thing to remember (and one of the reasons a lot of people switch to tibbles which are kind of data frames+. We’ll get to tibbles some time in the future) is that if you subset a single column the result will be a vector and not a dataframe. This sometimes is annoying if you are designing something that is supposed to work on data frames specifically.\nThere is one additional way of subsetting a data frame. Subsetting variables based on their position is tiresome because we rarely remember the order of all the columns (especially as our data frames get bigger). You can select a single variable using $:\n\npsych_books$author\n\n[1] \"Allport\" \"Heider\"  \"Lewin\"   \"Allport\" \"Heider\" \n\n\nUsing the $ operator reflects a way of thinking about datasets that is pretty common: data frames are ordered collections of variables and each variable has its name. You can also use $ to create new variables. Just assign a vector of values to a new name in your dataframe:\n\npsych_books$discipline <- c('intergroup relations', 'social psychology',\n                            'general psychology', 'social psychology',\n                            'biography')\npsych_books\n\n   author                                        title year\n1 Allport                          Nature of Prejudice 1954\n2  Heider        Psychology of interpersonal relations 1958\n3   Lewin         Principles of Topological Psychology 1936\n4 Allport                          Psychology of Rumor 1947\n5  Heider The life of a psychologist: An autobiography 1983\n            discipline\n1 intergroup relations\n2    social psychology\n3   general psychology\n4    social psychology\n5            biography\n\n\nRemember how we talked about element-wise operations on vectors? You can leverage it to easily create new variables that are results of operations on other variables. Thanks to this you can add a whole new variable that is a result of a mathematical operation in just one line (imagine adding a variable that is a sum of all points from a quiz for each student). Here’s an example if we wanted to calculate how many years ago each book from our data frame was published:\n\npsych_books$book_age <- 2022 - psych_books$year\npsych_books\n\n   author                                        title year\n1 Allport                          Nature of Prejudice 1954\n2  Heider        Psychology of interpersonal relations 1958\n3   Lewin         Principles of Topological Psychology 1936\n4 Allport                          Psychology of Rumor 1947\n5  Heider The life of a psychologist: An autobiography 1983\n            discipline book_age\n1 intergroup relations       68\n2    social psychology       64\n3   general psychology       86\n4    social psychology       75\n5            biography       39"
  },
  {
    "objectID": "03data_types.html#lists",
    "href": "03data_types.html#lists",
    "title": "Types of data",
    "section": "Lists",
    "text": "Lists\nLists are the final type of basic data in R we will discuss here. They are the most versatile ones - they can store anything inside of them: single values, vectors, matrices, dataframes or even other lists! One important feature of lists is that they are ordered: you can access their elements by position. So you can think of lists as collections of objects but there aren’t really limits to what these objects are (in fact dataframes are very specific lists: they are collections of variables that have the same length and form a nice rectangular table). Lists are created with list(). Lets create a list of the plants in a house along with a value storing information on how many days ago did we last water them:\n\nlist_of_objects <- list(\n  plants = c('Calathea', 'Chamedora', 'Pilea', 'Philodendron'),\n  days_since_watering = 5\n)\nlist_of_objects\n\n$plants\n[1] \"Calathea\"     \"Chamedora\"    \"Pilea\"        \"Philodendron\"\n\n$days_since_watering\n[1] 5\n\n\nYou might encounter lists if you need to store a number of different things together. E.g. results of many statistical analyses are stored in lists. In fact as you dive deeper into R you will start to encounter more and more lists because they are very versatile.\nYou can access objects stored in lists in a few ways. You can use the [] you used for all other types of data. An important feature of this type of subsetting is that the result will always be a list (even if it has only 1 element). The other option is to use double square brackets [[]]. This will extract the object inside a list so the result won’t be a list (you can think of it as ‘getting deeper’ into the list to extract the exact element you want).\n\nlist_of_objects[1]\n\n$plants\n[1] \"Calathea\"     \"Chamedora\"    \"Pilea\"        \"Philodendron\"\n\nlist_of_objects[[1]]\n\n[1] \"Calathea\"     \"Chamedora\"    \"Pilea\"        \"Philodendron\"\n\n\nIf the elements in your list are named you can also use $ to extract them.\\\n\nlist_of_objects$days_since_watering\n\n[1] 5"
  },
  {
    "objectID": "05functions.html#how-is-a-function-built",
    "href": "05functions.html#how-is-a-function-built",
    "title": "Functions",
    "section": "",
    "text": "The first approximation to how a function is built is to think of it as a kind of machine. The machine takes some inputs, processes them in some way and returns outputs. The inputs are the arguments you provide to a function like a vector or a dataset. The result is the output. Very often the insides of a function, the machinery within it that is responsible for getting from the input to the output is a black box to us. We have no clue how exactly a function arrives at its result. Sometimes we don’t need to know it but in many situations at least some knowledge is necessary to be certain that the function does exactly what we need it to do and won’t surprise us (an annoying example we will get to later is silent dropping of missing values by some functions)."
  },
  {
    "objectID": "05functions.html#types-of-arguments",
    "href": "05functions.html#types-of-arguments",
    "title": "Functions",
    "section": "",
    "text": "Lets focus on the inputs. There are a few kinds of them. The most basic ones are input arguments - this is what you put into the machine. Apart from it there are a few other types of arguments that can allow you to have more control over the behavior of functions. They are a bit like toggles and switches on a machine that change how it operates.\nDefault arguments: arguments that are set to some default value. This value will be used unless specified otherwise. An example is the na.rm argument from mean or sum. This argument is set to FALSE by default so that the function will return an error if there are any missing values in the input argument. This is such a good example because it also stresses why choosing proper defaults is really important when writing functions. A lot of people, when they first encounter functions like mean or sum, are surprised or even annoyed. Why in the world set defaults that are more likely to produce errors? We are often fixated on avoiding errors in code but this is not always the way to go in data analysis. We often want functions to operate smoothly and seamlessly. But that is false peace. Smooth behavior is not always what we need from functions. Clunky functions are often good in data analysis because they force us to be explicit with what we do with data. Even if they make climbing the hill a bit more steep they are sure to lead us on the right path to the top.\nYou can also encounter alternative arguments. These arguments have a prespecified set of possible values (usually defined as a vector).= For example the table() function that can give us a frequency table of a factor has a useNA argument that specifies whether to use NA values.It can take three different valus that specify possible behaviour of the function. You can read more onwhat they do inthe documentation of the function.\nThe final type of argument is the … argument. It is a placeholder for any number and kind of arguments that will later on be passed inside the function usually as arguments in some internal function. Take lapply as an example. Apart from the argument X and FUN which specify what to loop over and what function to apply to each element of X it also has the … argument. It’s there because the function you want to apply to every element of X might take some additional arguments. How many and what kind of arguments these are might vary from function to function and the … argument allows us to handle this. Any arguments passed in the … will be used as argument of the function specified in the FUN argument of lapply."
  },
  {
    "objectID": "05functions.html#building-your-own-functions",
    "href": "05functions.html#building-your-own-functions",
    "title": "Functions",
    "section": "",
    "text": "Why spend time building your own functions? There are a few general cases. The first and probably most obvious one is when there is no available function that would do what you need. For example there is no available function to find a mode of a vector in R. If you want to find it you need to build your own function. Finding a mode is a simple example but there may be cases where you need to do something more complex or customize the behavior of an already existing function. Second reason is to avoid repetition. If you do similar operations a number of times (e.g. only the dataset or vriables change but all the rest stays the same) then copying and pasting code will soon become problematic. It makes code less readable, longer and more difficult to manage. Imagine you need to change one thing in that code. You’ll need to change it in every place where it was pasted. Writing a function instead means you can just change how you define the function.\nThe general logic for defining a function is as follows:\n\nmy_function &lt;- function(arguments) {\n  #what the function does\n}\n\nTurning a chunk of code into a function can be done quite easily in a few steps. Imagine we want to see what is the probability that a random number drawn from one vector will be larger than the mean of another vector (we will simulate a few variables with rnorm() which draws random numbers from a normal distribution with a given mean and standard deviation):\n\n#simulate vectors\nvar1 &lt;-rnorm(100, 0, 1)\nvar2 &lt;- rnorm(100, 1, 3)\nvar3 &lt;- rnorm(100, .5, 2)\nvar4 &lt;- rnorm(100, 0, 3)\nvar5 &lt;- rnorm(100, 0.1, .2)\n\n#calculate mean\nmean_1 &lt;- mean(var1)\n\n#calculate lenght\nlength_2 &lt;- length(var2)\n\n#calculate how many values in var2 are larger than mean_1\n\nn_larger &lt;- length(var2[var2 &gt; mean_1])\n\n#get the proportion\n\nn_larger/length_2\n\n[1] 0.57\n\n\n\nBuild the scaffolding of the function. This is exactly what is in the code chunk above:\n\nmy_function &lt;- function(arguments) {\n  #what the function does\n}\n\nPaste the code you want to turn into a function\n\nmy_function &lt;- function(arguments) {\n#calculate mean\nmean_1 &lt;- mean(var1)\n\n#calculate lenght\nlength_2 &lt;- length(var2)\n\n#calculate how many values in var2 are larger than mean_1\n\nn_larger &lt;- length(var2[var2 &gt; mean_1])\n\n#get the proportion\n\nn_larger/length_2\n}\n\nIdentify all the “moving parts”: What will change? Each of these things has to get its own argument (all the moving parts are marked on the right side of the code chunk):\n\nmy_function &lt;- function(arguments) {\n#calculate mean\n1mean_1 &lt;- mean(var1)\n\n#calculate lenght\n2length_2 &lt;- length(var2)\n\n#calculate how many values in var2 are larger than mean_1\n\n3n_larger &lt;- length(var2[var2 &gt; mean_1])\n\n#get the proportion\n\nn_larger/length_2\n}\n\n\n1\n\nvar_1\n\n2\n\nvar_2\n\n3\n\nvar_2\n\n\n\n\nChange each of the “moving parts” in the code chunk into appropriate argument\n\nmy_function &lt;- function(x, y) {\n#calculate mean\nmean_1 &lt;- mean(y)\n\n#calculate lenght\nlength_2 &lt;- length(x)\n\n#calculate how many values in var2 are larger than mean_1\n\nn_larger &lt;- length(x[x &gt; mean_2])\n\n#get the proportion\n\nn_larger/length_2\n}\n\n\n\n\nWhen building your own functions, especially if they are going to be used by other people, it’s a good idea to consider potential weird things that could happen. When first creating a function we usually have its typical behaviour in mind because we just want our function to work. However, there’s a whole bunch of weird stuff that might happen if you don’t prepare for it in advance. For example, imagine you want to create a function from scratch that will output the mean of a numeric vector. You could try to do something like a for loop (yes this is slow and inefficient but it’s just for the purpose of demonstration):\n\nmy_mean &lt;- function(x) {\n  sum &lt;- 0\n  for(i in x){\n    sum &lt;- sum + i\n  }\n  result &lt;- sum/length(x)\n  return(result)\n}\n\nPretty straightforward right? Now lets see our function in action on some typical use case and compare its results to the built-in mean() function:\n\nv &lt;- c(1,2,3,4,5,6,7,8,9)\n\nmy_mean(v)\n\n[1] 5\n\nmean(v)\n\n[1] 5\n\n\nYay, we get the same result! Seems like our function works! But before we call it a day and start using our own mean function lets see some less typical cases. E.g. What will happen if the vector has some missing values? Or if its an empty vector? Or if it is not a numeric vector? Lets see:\n\nv_na &lt;- c(1,2,3,NA,5)\nv_empty &lt;- c()\nv_char &lt;- c(\"A\", \"B\", \"C\")\n\nmy_mean(v_na)\n\n[1] NA\n\nmy_mean(v_empty)\n\n[1] NaN\n\nmy_mean(v_char)\n\nError in sum + i: argument nieliczbowy przekazany do operatora dwuargumentowego\n\n\nWe get some weird behaviour. Each of these calls to my_mean() function returned something different. First we got NA when the vector had NAs in it. Passing an empty vector resulted in NaN - short for Not a Number. Finally, passing a character vector gave us an error.. Notice that only the last case gave us an error so if we then implemented our functions in some calculations we might not even notice something is wrong - for example imagine we calculated a mean with our function from a vector with missiing values (e.g we asked a bunch of participants about their mood 5 times a day and now we want to calculate daily average mood and see how it relates to some variables of interest) and then tried to use its output in some other function that had na.rm argument set to TRUE. We’d lose a bunch of information without so much as a warning! That`s why considering possible but unusual cases for a new function is important. It allows us to prepare for possible future problems."
  },
  {
    "objectID": "05functions.html#anonymous-functions",
    "href": "05functions.html#anonymous-functions",
    "title": "Functions",
    "section": "",
    "text": "There are situations in which you might want to use a custom function but not necessarily save it with a name for future use. In such situations we often use what is called an anonymous function (sometimes you can also encounter the term lambda functions). The general way these functions are constructed in R is as follows:\n\n(function(x) WHAT THE FUCNTION DOES)(arguments)\n\nA pretty common situation where you can also encounter these functions is inside iterations like with apply:\n\nv1 &lt;- c(1,2,3,4)\nv2 &lt;- c(3,4,5,6,8)\nv3 &lt;- c(-1,4,3,2)\nv_list &lt;- list(v1,v2,v3)\n\nlapply(v_list, function(x) {x+x})\n\n[[1]]\n[1] 2 4 6 8\n\n[[2]]\n[1]  6  8 10 12 16\n\n[[3]]\n[1] -2  8  6  4"
  },
  {
    "objectID": "05functions.html#documentation",
    "href": "05functions.html#documentation",
    "title": "Functions",
    "section": "",
    "text": "Ok, so we wrote our super cool new function. We tested it and are pretty confident it works properly. Can we finally call it a day? Again, not so fast. We need one more thing. Imagine you take a long holiday and get back towork after a month or two, How confident are you you will remember how exactly our new function works? Or imagine you share the function you ccreated with other people .Of course you (or others) can read the code of the function to learn that again but that is tedious. That`s why it’s so important to document code. This goes for functions but is just as true for any code that will be used by others or you in the future. Treat yourself in the future like you would treat another person. Documentation is super important! For a lot of people writing (or reading!) documentation is seen as tedious and redundant task. I guarantee you that if you don’t document your own functions you will regret this sooner or later (probably sooner). Very few functions are self explanatory enough to not need any form of documentation. In many cases simply using comments in code with # will be enough. Sometimes building vignettes that shows how to use some functions can be a better idea. Remember to always leave some description of what given code is about and what it does."
  },
  {
    "objectID": "05functions.html#functions-from-packages",
    "href": "05functions.html#functions-from-packages",
    "title": "Functions",
    "section": "",
    "text": "Since R has a huge community people are constantly developing new things you can do in R. You don’t have to define everything from scratch. Usually if you need a function for some statistical procedure or e.g. for plotting some package out there already has it. There is no need to reinvent the wheel.\nIn order to use functions from packages you need to first install the package on your computer. You can do it by calling install.packages(\"PACKAGENAME\") functon. You need to do it only once on a given device (unless you want to update the package or you are using renv but more on that later). Once the package has been installed you can load it in a given R session by calling library(PACKAGENAME). Remember you need to run it every time you open a new R session. Alternatively, after installing a package you can call a function from it directly without loading the package first by using PACKAGENAME::function_name().\nAnother thing to know about functions from packages is name conflict. Since R is open source and most of the packages are developed and maintained by the community it is not so uncommon that two different packages have a function with the same name. You might wonder what will happen if you load both packages and then call this function? Generally, the last package loaded is going to mask previous packages. However this can be problematic e.g. if you are sharing scripts (and someone changes the order of loading packages) or if you actually want to use the function from the first package.\nThere are at least two ways of dealing with this problem. The first one is to be explicit. Above we described a second way of calling a function from a package: PACKAGENAME::function_name(). This way you explicitly state which package the function is from so you shield yourself from name conflict. The second way is by specifying additional arguments to the library() function. If you look up its documentation you can see that it has two optional arguments: exlcude and include.only. They allow you to load a package without some function or to load only some functions from a package. This is useful in situations where you want to load 2 packages with conflicting functions but you know you want to use the conflicting function from only one of them."
  },
  {
    "objectID": "05functions.html#exercises",
    "href": "05functions.html#exercises",
    "title": "Functions",
    "section": "",
    "text": "Remember the for loop that generated n first numbers from Fibonacci sequence from the class on loops? Now turn it into a function that will return from ith to jth Fibonacci number. Document the function properly so it is clear what it does\nCreate a function that calculates a mode of a vector. Consider potential edge cases and provide tests that show your function behaves properly"
  },
  {
    "objectID": "04loops_conditionals.html#conditional-statements",
    "href": "04loops_conditionals.html#conditional-statements",
    "title": "Loops and conditionals",
    "section": "",
    "text": "Another way conditional statements are referred to which may be more intuitive are if else statements. They allow you to tell R to execute given chunk of code if a condition is met and to do something else if the condition is not met.\nThe general logic of conditional statements looks like this:\n\nif (condition) {\n  Do this\n  And do this\n}\n\nA single if statement can have multiple conditions chained together with | and & operators. So, for example\n\nx &lt;- 5\ny &lt;- -5\n\nif (x &gt; 0 & y &lt; 0) {\n  print(\"Hooray!\")\n}\n\n[1] \"Hooray!\"\n\n\nIn many situations you want to state what is to be done if a condition is met and what to do otherwise. This turns your statement into an if else one. The only difference is that after the if statement you add else and specify what to do then in curly brackets. With this knowledge you can already create the rules for a simple game like paper, rock, scissors!\n\n#set the choice for each player\nplayer1 &lt;- 'scissors'\nplayer2 &lt;- 'rock'\n\n#define an if statement that outputs the result of the game\nif (player1 == player2) {\n  print('draw')\n} else if ((player1 == 'scissors' & player2 == 'paper') |\n           (player1 == 'paper' & player2 == 'rock') |\n           (player1 == 'rock' & player2 == 'scissors')) {\n  print('player 1 wins')\n} else if ((player2 == 'scissors' & player1 == 'paper') |\n           (player2 == 'paper' & player1 == 'rock') |\n           (player2 == 'rock' & player1 == 'scissors')) {\n  print('player 2 wins')\n} else {\n  print('these are not allowed moves')\n}\n\n[1] \"player 2 wins\"\n\n\nTake a moment to study the code above. Notice what kinds of conditions are included in that statement. When writing an if statement it’s a good idea to consider all possible situations and how your if statement maps to them. In a paper, rock, scissors game you can have 3 outcomes: both players choose the same option (a draw), player 1 wins or player 2 wins. Notice that the code above includes also a fourth options specified in the last else statement. What if someone makes a typo and writes rook instead of rock? That last else statement safeguards us for such situations. If we didn’t include it and someone made a type then our if else statement wouldn’t produce anything. You can play around with different values of player1 and player2 to see the results.\nOne more thing about if else statements: in many situations it is a good idea to give some thought to what exactly a given statement is supposed to do and how large the statement needs to be. A good example is an if statement that is supposed to run some check (e.g. make sure that we are working with a numeric value) and stop execution if it detects a problem. Imagine a situation in which we want to do some calculations on numbers and want to make sure that we are indeed working with numeric values. you could design an if else statement that would do it:\n\nx &lt;- 'not a number'\ny &lt;- 3\nif ((class(x) != 'numeric') | (class(y) != 'numeric')) {\n  stop('This is not a number!')\n} else {\n  x + y\n}\n\nError in eval(expr, envir, enclos): This is not a number!\n\n\nTake a moment to look at the code above. Do you think it is good? It certainly gets the job done. Do you think it could be simplified?\nIn fact the else part is redundant in this case. The if statement runs the check on x and y and stops execution of the code if any of them is not numeric. If both values are numeric the execution of code simply proceeds. In this case adding an else statement makes the code harder to read (and imagine what would happen if we had to perform a number of checks like this! We would need a lot of if else statements that would make everything even less clear). The code below does the same thing as the if else statement above but is more clear.\n\nx &lt;- 'not a number'\ny &lt;- 3\nif ((class(x) != 'numeric') | (class(y) != 'numeric')) {\n  stop('This is not a number!')\n}\n## Error in eval(expr, envir, enclos): This is not a number!\nx + y\n## Error in x + y: argument nieliczbowy przekazany do operatora dwuargumentowego"
  },
  {
    "objectID": "04loops_conditionals.html#loops",
    "href": "04loops_conditionals.html#loops",
    "title": "Loops and conditionals",
    "section": "",
    "text": "Another way of controlling the flow of your code is by repeating a given chunk of code. There are two basic ways to do that: repeat something a number of times or keep repeating until some condition is met. The first way is called a for loop and the second one a while loop.\n\n\nBefore we make our first for loop lets take a moment to see when a for loop is not needed. Recall again that a lot of things in R are vectorized. This means that operations on vectors are conducted element-wise. Thanks to this if you want to e.g. add 5 to each value stored in a numeric vector (in the language of a for loop: for every element of a vector, add 5 to it) you can just write vector_name + 5. No need for more complicated, explicit repetition. However, there are situations in which you have to make an explicit for loop to repeat something n times. The general structure of a for loops looks like this:\n\nfor (i in object) {\n  Do this to each element\n}\n\nIt’s worth keeping in mind what the i in the for loop is. In the example above i will be every consecutive element of object. However we could do a similar thing with:\n\nfor (i in 1:length(object)) {\n  do this to object[i]\n}\n\nNow each i is a number from 1 to thew length of object and we access each element of object by using a proper (ith) index. Which way of running a for loop you choose might depend on the context. looping explicitly over elements of an object rather than indexes can be more intuitive but imagine you don’t want to do something to every element of an object but only to to a subset (e.g. from 3rd onwards). Doing it with indexes is easier. Generally the best approach is to think what you need first and code second, not the other way around.\n\n\n\nWhile loops will keep executing a given chunk of code as long as some condition is met.\nWe can use a while loop to make a very simple simulation. Lets say we want to see how temperatures change from a given temperature (lets say 20 degrees Celsius) across time and that we represent time by some random change from each previous temperature. We can create a vector with such predicted temperatures and see how long it takes for it to reach a certain level (lets say 30 degrees Celsius). We represent the change by adding a random value from a normal distribution with mean = .05 and standard deviation = .5 (this is what the rnorm(1,.05,.5) does). The while loop would look something like this. We first create the initial value and a vector to store all temperatures and next we keep adding the random value to our temperature and storing all temperatures until it reaches 30. The last line tells R to plot all the temperatures as a line plot. This is of course a very, very very simplistic simulation (temperatures don’t change in such a simple way) but it works to show you the idea behind while loops. We can then calculate e.g. how long it took for the temperature to reach a certain level.\n\nC &lt;- 20\nresults &lt;- c(20)\nwhile (C &lt; 30) {\n  C &lt;- C + rnorm(1,.05,.5)\n  results &lt;- c(results, C)\n}\n\nplot(results, type = 'line', lwd = 2, col=4, xlab = \"days\", ylab = \"temperature\")\n\nWarning in plot.xy(xy, type, ...): plot type 'line' will be truncated to first\ncharacter\n\n\n\n\n\nBecause while loops do not have a fixed number of iteration they can potentially run infinitely. This is usually not something we want so it’s a good idea to make sure that your while loop eventually stops. In case you do get stuck in an infinite loop you can press Esc in your console and this should make RStudio stop the loop by force.\nTruth is while loops are not common in R. You will rarely find yourself in situation where you need to perform some actions while a given condition is true (e.g. keep a program running until a user presses exit; keep displaying a board of a game until a player makes a move). However, it’s still good to know what while loops are so that you will know one when you see it."
  },
  {
    "objectID": "04loops_conditionals.html#apply-family",
    "href": "04loops_conditionals.html#apply-family",
    "title": "Loops and conditionals",
    "section": "",
    "text": "There is a special family of functions in R that makes working with for loops a bit easier. These functions let you specify what to loop over and what function to apply to each element but in a function rather than a whole loop with all the curly brackets and stuff.\nThe reason why this is a whole family of functions is that you can iterate in various ways and you can get the output in different formats. There are more functions in the family but the general ones are:\n\nlapply() - loops over elements of a vector/list and returns a list\nsapply() - same as lapply but tries to simplify the result to a vector or matrix\napply() - used for looping over 2 dimensional structures - it lets you specify if you want to loop over rows or columns\ntapply() - same as apply but lets you split the object you are looping over based on some factor (e.g. imagine you want to calculate the mean value of your dependent variable for each experimental condition).\n\nLets see some of these in action.\nExample 1:\nImagine you are working with a list in R. You want to get information on how many elements each object in the list has. sapply makes it very easy:\n\nmy_list &lt;- list(\n  1:50,\n  sample(300, 5),\n  c(\"random\", \"vector\")\n)\n\nsapply(my_list, length)\n\n[1] 50  5  2\n\n\nExample 2:\nThere is a dataset available in R on airquality in New York City called airquality. It stores information on ozone, sun, wind and temperature from 5 months One of the things that might be of interest when looking at the dataset is what was the average value of each of the variables informing on airquality:\n\ndata(\"airquality\")\nd &lt;- airquality\nd &lt;- na.omit(d)\napply(d[,1:4], 2, mean)\n\n    Ozone   Solar.R      Wind      Temp \n 42.09910 184.80180   9.93964  77.79279 \n\n\nNotice that the means calculated above are global means from the entire dataset. What is probably much more sensible is a mean for each month. There is one additional trick needed here. Tapply won’t allow us to split a number of columns by some vector and perform a given operation on each of the columns. That’s because tapply works on vectors. In order to get monthly means for all 4 columns we need to combine apply with tapply. What we need to do is start with apply and loop over the 4 columns of interest and for each of them use tapply that will split a given column by month and calculate the means. Combining functions can get us really far if only we give some thought to what each function does (including what are its inputs and outputs) and what we really need to do.\n\napply(d[,1:4], 2, function(x) tapply(x, d$Month, mean))\n\n     Ozone  Solar.R      Wind     Temp\n5 24.12500 182.0417 11.504167 66.45833\n6 29.44444 184.2222 12.177778 78.22222\n7 59.11538 216.4231  8.523077 83.88462\n8 60.00000 173.0870  8.860870 83.69565\n9 31.44828 168.2069 10.075862 76.89655"
  },
  {
    "objectID": "04loops_conditionals.html#exercises",
    "href": "04loops_conditionals.html#exercises",
    "title": "Loops and conditionals",
    "section": "",
    "text": "Try to code the logic of assigning points to players of a prisoner dilemma with a given matrix:\n\nCreate a for loop that will print out the first 50 numbers from the Fibonacci sequence\nGiven the iris dataframe (you can load it with data(\"iris\") loop over all of its columns and calculate the mean of every numeric column"
  },
  {
    "objectID": "06loading_data.html#loading-data-in-r",
    "href": "06loading_data.html#loading-data-in-r",
    "title": "loading_data",
    "section": "",
    "text": "There are many ways of loading a dataset or file into your R session so that you can use it. How to do it depends mainly on how the data is stored.\nWhen loading a dataset there are generally a few things to consider."
  },
  {
    "objectID": "17linear_models.html",
    "href": "17linear_models.html",
    "title": "Linear Models",
    "section": "",
    "text": "-what is a linear model?\n-How to think about linear models\n-Basics of specifying a linear model\n-T-test, between-anova and regression are the same thing - a linear model\n-Buiding a simple linear model\n-Adding predictors\n-Categorical predictors"
  },
  {
    "objectID": "17linear_models.html#linear-models",
    "href": "17linear_models.html#linear-models",
    "title": "Linear Models",
    "section": "",
    "text": "-what is a linear model?\n-How to think about linear models\n-Basics of specifying a linear model\n-T-test, between-anova and regression are the same thing - a linear model\n-Buiding a simple linear model\n-Adding predictors\n-Categorical predictors"
  },
  {
    "objectID": "18statistical_control.html",
    "href": "18statistical_control.html",
    "title": "Statistical control",
    "section": "",
    "text": "-What is statistical control?\n-To control or not to control - confounders"
  },
  {
    "objectID": "19postprocessing.html",
    "href": "19postprocessing.html",
    "title": "Postprocessing results",
    "section": "",
    "text": "-general logic of working with results in R: you get a saved object\n-Making predictions\n-Marginal effects\n-Contrasts\n-reporting?"
  }
]